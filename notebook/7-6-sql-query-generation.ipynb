{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SQL Query Generation and Execution with LangGraph\n\n## Introduction\n\nThis notebook demonstrates how to use LangChain, OpenAI, and SQLDatabaseToolkit to generate and execute SQL queries based on natural language questions. The workflow involves initializing a SQL database, defining tools for querying and schema retrieval, and setting up a stateful graph to manage the query generation and execution process. The notebook also includes error handling and result formatting to ensure a smooth user experience.","metadata":{}},{"cell_type":"markdown","source":"## Installation and Setup\n\nFirst, we need to install the necessary libraries and import the required modules.\n\nThese installations set up the necessary environment for:\n- Interacting with **OpenAI** and **Anthropic** language models.\n- Using **LangChain tools** for database interactions and workflow management.\n- Building **stateful workflows** with `langgraph`.\n- Optional use of **vector databases** like ChromaDB for advanced tasks.\n\nThis ensures that all dependencies are available for the notebook to function correctly.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langgraph\n!pip install -qU chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:14:01.658755Z","iopub.execute_input":"2025-01-13T11:14:01.659341Z","iopub.status.idle":"2025-01-13T11:14:25.512046Z","shell.execute_reply.started":"2025-01-13T11:14:01.659302Z","shell.execute_reply":"2025-01-13T11:14:25.510585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary modules\nfrom langchain_community.utilities import SQLDatabase\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.messages import ToolMessage, AIMessage\nfrom langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import AnyMessage, add_messages\nfrom pydantic import BaseModel, Field\nfrom typing import Annotated, Literal, TypedDict, Any","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initialize the Database\n\nWe will be creating a SQLite database for this tutorial. SQLite is a lightweight database that is easy to set up and use. We will be loading the chinook database, which is a sample database that represents a digital media store. Find more information about the database [here](https://www.sqlitetutorial.net/sqlite-sample-database/).","metadata":{}},{"cell_type":"code","source":"import requests\n\nurl = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\nresponse = requests.get(url)\n\nif response.status_code == 200:\n    # Open a local file in binary write mode\n    with open(\"Chinook.db\", \"wb\") as file:\n        # Write the content of the response (the file) to the local file\n        file.write(response.content)\n    print(\"File downloaded and saved as Chinook.db\")\nelse:\n    print(f\"Failed to download the file. Status code: {response.status_code}\")\n\n# Initialize the database\ndb = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\nprint(f\"Database Type: {db.dialect}\")\nprint(f\"Tables: {db.get_usable_table_names()}\")\nprint(f\"Artist: {db.run('SELECT * FROM Artist LIMIT 5;')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:15:37.44646Z","iopub.execute_input":"2025-01-13T11:15:37.447002Z","iopub.status.idle":"2025-01-13T11:15:37.685132Z","shell.execute_reply.started":"2025-01-13T11:15:37.446945Z","shell.execute_reply":"2025-01-13T11:15:37.684008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Tools for the Agent\n\nNext, we define the tools that the agent will use to interact with the database. These tools include querying the database, retrieving the schema, and listing tables.\n\nThis code:\n1. Securely loads the OpenAI API key.\n2. Initializes a `SQLDatabaseToolkit` with the necessary tools for interacting with a SQL database.\n3. Extracts specific tools for querying, schema retrieval, and table listing.\n4. Binds a language model to the schema tool for handling schema-related tasks.\n\nThis setup enables the agent to:\n- Execute SQL queries.\n- Retrieve database schema and table information.\n- Check SQL queries for correctness.\n- Use OpenAI's language model to assist in database interactions.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\n# Load OpenAI API Key\nmy_api_key = UserSecretsClient().get_secret(\"my-openai-api-key\")\n\n# Define tools for the agent\ntoolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=\"gpt-4o-mini\", api_key=my_api_key))\ntools = toolkit.get_tools()\n\n# Extract specific tools from the toolkit\ndb_query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")\ndb_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\ndb_list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\ndb_query_checker_tool = next(tool for tool in tools if tool.name == \"sql_db_query_checker\")\n\n# Bind the schema tool to a model\ndb_schema_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=my_api_key).bind_tools([db_schema_tool])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:30.924991Z","iopub.execute_input":"2025-01-13T11:25:30.925402Z","iopub.status.idle":"2025-01-13T11:25:31.372283Z","shell.execute_reply.started":"2025-01-13T11:25:30.925369Z","shell.execute_reply":"2025-01-13T11:25:31.371045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Workflow State\n\nWe define the state of the workflow, which will keep track of the messages exchanged during the query generation and execution process.","metadata":{}},{"cell_type":"code","source":"# Define the workflow state\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.373642Z","iopub.execute_input":"2025-01-13T11:25:31.374096Z","iopub.status.idle":"2025-01-13T11:25:31.379093Z","shell.execute_reply.started":"2025-01-13T11:25:31.374059Z","shell.execute_reply":"2025-01-13T11:25:31.377808Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Initial Tool Node\n\nThe initial tool node is responsible for starting the workflow by listing the tables in the database.","metadata":{}},{"cell_type":"code","source":"# Define the initial tool node\ndef initial_tool_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Initializes the workflow by creating a tool call to list tables in the database.\n    \"\"\"\n    tool_call_id = \"tool_abcd123\"  # Hardcoded for debugging\n    print(f\"--- First Tool Call Node ---\\nTool Call ID: {tool_call_id}\")\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": tool_call_id,\n                    }\n                ],\n            )\n        ]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.381141Z","iopub.execute_input":"2025-01-13T11:25:31.381436Z","iopub.status.idle":"2025-01-13T11:25:31.40489Z","shell.execute_reply.started":"2025-01-13T11:25:31.381412Z","shell.execute_reply":"2025-01-13T11:25:31.403778Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the List Tables Node\n\nThis node lists all tables in the database and returns the result as a ToolMessage.","metadata":{}},{"cell_type":"code","source":"# Define the list tables node\ndef list_tables_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Lists all tables in the database and returns the result as a ToolMessage.\n    \"\"\"\n    print(\"--- List Tables Node ---\")\n    result = db_list_tables_tool.invoke({})\n    print(\"Tables in the database:\", result)\n\n    # Get the tool_call_id from the previous message\n    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n    print(f\"Tool Call ID: {tool_call_id}\")\n    return {\"messages\": [ToolMessage(content=result, tool_call_id=tool_call_id)]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.406938Z","iopub.execute_input":"2025-01-13T11:25:31.407315Z","iopub.status.idle":"2025-01-13T11:25:31.431107Z","shell.execute_reply.started":"2025-01-13T11:25:31.407285Z","shell.execute_reply":"2025-01-13T11:25:31.429948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Model Get Schema Node\n\nThis node uses the model to generate a schema request based on the current state.","metadata":{}},{"cell_type":"code","source":"# Define the model get schema node\ndef model_get_schema_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Uses the model to generate a schema request based on the current state.\n    \"\"\"\n    print(\"--- Model Get Schema Node ---\")\n    return {\"messages\": [db_schema_model.invoke(state[\"messages\"])]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.432207Z","iopub.execute_input":"2025-01-13T11:25:31.432604Z","iopub.status.idle":"2025-01-13T11:25:31.458414Z","shell.execute_reply.started":"2025-01-13T11:25:31.432567Z","shell.execute_reply":"2025-01-13T11:25:31.457204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Retrieve Schema Node\n\nThis node retrieves the schema for a specific table and returns it as a ToolMessage.","metadata":{}},{"cell_type":"code","source":"# Define the retrieve schema node\ndef retrieve_schema_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Retrieves the schema for a specific table and returns it as a ToolMessage.\n    \"\"\"\n    print(\"--- Retrieve Schema Node ---\")\n    table_name = state[\"messages\"][-1].tool_calls[0][\"args\"][\"table_names\"]\n    result = db_schema_tool.invoke(table_name)\n    print(f\"Schema for table '{table_name}':\\n{result}\")\n\n    # Get the tool_call_id from the previous message\n    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n    print(f\"Tool Call ID: {tool_call_id}\")\n\n    # Return a ToolMessage with the same tool_call_id\n    return {\"messages\": [ToolMessage(content=result, tool_call_id=tool_call_id)]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.459589Z","iopub.execute_input":"2025-01-13T11:25:31.459936Z","iopub.status.idle":"2025-01-13T11:25:31.47886Z","shell.execute_reply.started":"2025-01-13T11:25:31.45991Z","shell.execute_reply":"2025-01-13T11:25:31.477719Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the SubmitFinalAnswer Class\n\nThis class represents the final answer to be submitted to the user.","metadata":{}},{"cell_type":"code","source":"# Define the SubmitFinalAnswer class\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"\n    A Pydantic model representing the final answer to be submitted to the user.\n    \"\"\"\n    final_answer: str = Field(..., description=\"The final answer to the user\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.480058Z","iopub.execute_input":"2025-01-13T11:25:31.480415Z","iopub.status.idle":"2025-01-13T11:25:31.499366Z","shell.execute_reply.started":"2025-01-13T11:25:31.480383Z","shell.execute_reply":"2025-01-13T11:25:31.498288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Query Generation System Prompt\n\nThis prompt guides the model in generating SQL queries based on the input question. \n\nThis code sets up a **query generation pipeline**:\n1. The model acts as a SQL expert and generates SQL queries based on the input question.\n2. The query is generated with strict guidelines to ensure correctness, relevance, and safety.\n3. The final answer is submitted using the `SubmitFinalAnswer` tool.\n\nThis system ensures that:\n- SQL queries are **accurate and optimized**.\n- Results are **limited and relevant**.\n- Errors and edge cases are **handled gracefully**.\n- The workflow adheres to **best practices** (e.g., no DML statements).","metadata":{}},{"cell_type":"code","source":"# Define the query generation system prompt\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set.\nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen_chain = query_gen_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=my_api_key).bind_tools([SubmitFinalAnswer])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.502943Z","iopub.execute_input":"2025-01-13T11:25:31.503241Z","iopub.status.idle":"2025-01-13T11:25:31.689435Z","shell.execute_reply.started":"2025-01-13T11:25:31.503217Z","shell.execute_reply":"2025-01-13T11:25:31.688338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Query Generation Node\n\nThis node generates a SQL query based on the current state and returns the result.\n\n1. Validates the input state to ensure it contains a `ToolMessage`.\n2. Generates an SQL query using the `query_gen_chain`.\n3. Handles errors if the wrong tool is called during query generation.\n4. Returns the generated query or error messages as part of the workflow state.\n\nThis node plays a critical role in the workflow by ensuring that SQL queries are generated correctly and that errors are handled gracefully.","metadata":{}},{"cell_type":"code","source":"# Define the query generation node\ndef query_gen_node(state: State):\n    \"\"\"\n    Generates a SQL query based on the current state and returns the result.\n    \"\"\"\n    print(\"--- Query Gen Node ---\")\n    # Ensure the last message is a ToolMessage\n    if isinstance(state[\"messages\"][-1], ToolMessage):\n        tool_call_id = state[\"messages\"][-1].tool_call_id\n        print(f\"Tool Call ID from previous message: {tool_call_id}\")\n    else:\n        raise ValueError(\"Expected a ToolMessage as the last message.\")\n\n    # Generate the query\n    message = query_gen_chain.invoke(state)\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.690873Z","iopub.execute_input":"2025-01-13T11:25:31.691195Z","iopub.status.idle":"2025-01-13T11:25:31.69846Z","shell.execute_reply.started":"2025-01-13T11:25:31.691169Z","shell.execute_reply":"2025-01-13T11:25:31.697009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Should Continue Function\n\nThis function determines the next step in the workflow based on the current state.","metadata":{}},{"cell_type":"code","source":"# Define the should_continue function\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    \"\"\"\n    Determines the next step in the workflow based on the current state.\n    \"\"\"\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.699451Z","iopub.execute_input":"2025-01-13T11:25:31.699873Z","iopub.status.idle":"2025-01-13T11:25:31.723629Z","shell.execute_reply.started":"2025-01-13T11:25:31.699835Z","shell.execute_reply":"2025-01-13T11:25:31.722543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the DB Statement Execution Tool\n\nThis tool executes a SQL query against the database and returns the result.","metadata":{}},{"cell_type":"code","source":"# Define the db_stmt_exec_tool function\n@tool\ndef db_stmt_exec_tool(query: str) -> str:\n    \"\"\"\n    Execute a SQL query against the database and return the result.\n    If the query fails, return an error message.\n    \"\"\"\n    result = db.run_no_throw(query)\n    if not result:\n        return \"Error: Query failed. Please rewrite your query and try again.\"\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.724694Z","iopub.execute_input":"2025-01-13T11:25:31.725165Z","iopub.status.idle":"2025-01-13T11:25:31.749089Z","shell.execute_reply.started":"2025-01-13T11:25:31.725129Z","shell.execute_reply":"2025-01-13T11:25:31.747891Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Query Check System Prompt\n\nThis prompt guides the model in checking the SQL query for common mistakes.\n\n1. The model acts as a SQL expert and checks the query for common mistakes.\n2. If mistakes are found, the query is rewritten; otherwise, the original query is used.\n3. The validated query is passed to the `db_stmt_exec_tool` for execution.\n\nThis ensures that only **correct and safe SQL queries** are executed on the database, reducing the risk of errors or unintended behavior.","metadata":{}},{"cell_type":"code","source":"# Define the query check system prompt\nquery_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\nDouble check the SQLite query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n\nYou will call the appropriate tool to execute the query after running this check.\"\"\"\n\nquery_check_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n)\nquery_check_chain = query_check_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=my_api_key).bind_tools([db_stmt_exec_tool], tool_choice=\"required\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.750374Z","iopub.execute_input":"2025-01-13T11:25:31.750745Z","iopub.status.idle":"2025-01-13T11:25:31.963023Z","shell.execute_reply.started":"2025-01-13T11:25:31.750707Z","shell.execute_reply":"2025-01-13T11:25:31.961841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Correct Query Node\n\nThis node corrects the SQL query if necessary and returns the corrected query.","metadata":{}},{"cell_type":"code","source":"# Define the correct query node\ndef correct_query_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Corrects the SQL query if necessary and returns the corrected query.\n    \"\"\"\n    print(\"--- Correct Query Node ---\")\n    return {\"messages\": [query_check_chain.invoke({\"messages\": [state[\"messages\"][-1]]})]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.964069Z","iopub.execute_input":"2025-01-13T11:25:31.964461Z","iopub.status.idle":"2025-01-13T11:25:31.97017Z","shell.execute_reply.started":"2025-01-13T11:25:31.964422Z","shell.execute_reply":"2025-01-13T11:25:31.968897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define the Execute Query Node\n\nThis node executes the SQL query and returns the result as a ToolMessage.","metadata":{}},{"cell_type":"code","source":"# Define the execute query node\ndef execute_query_node(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Executes the SQL query and returns the result as a ToolMessage.\n    \"\"\"\n    print(\"--- Execute Query Node ---\")\n    try:\n        query = state[\"messages\"][-1].tool_calls[0][\"args\"][\"query\"]\n        result = db_stmt_exec_tool.invoke(query)\n        print(f\"Query Results:\\n{result}\")\n    except Exception as e:\n        result = f\"Error: {str(e)}\"\n        print(result)\n\n    # Get the tool_call_id from the previous message\n    tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n    print(f\"Tool Call ID: {tool_call_id}\")\n    return {\"messages\": [ToolMessage(content=result, tool_call_id=tool_call_id)]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.971248Z","iopub.execute_input":"2025-01-13T11:25:31.971541Z","iopub.status.idle":"2025-01-13T11:25:31.991225Z","shell.execute_reply.started":"2025-01-13T11:25:31.971517Z","shell.execute_reply":"2025-01-13T11:25:31.990157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Workflow\n\nWe define the workflow by adding nodes and edges to the state graph. This code defines a **stateful, step-by-step workflow** for generating and executing SQL queries. The workflow:\n1. Starts by listing database tables.\n2. Retrieves the schema for a specific table.\n3. Generates and corrects SQL queries.\n4. Executes the queries and handles errors or corrections.\n5. Visualizes the entire workflow as a diagram for better understanding.\n\nThe workflow is designed to be modular, with each node handling a specific task, and conditional edges ensuring the correct flow based on the state of the process.","metadata":{}},{"cell_type":"code","source":"# Define the workflow\nworkflow = StateGraph(State)\n\n# Add nodes with redesigned names\nworkflow.add_node(\"initial_tool_node\", initial_tool_node)\nworkflow.add_node(\"list_tables_node\", list_tables_node)\nworkflow.add_node(\"model_get_schema_node\", model_get_schema_node)\nworkflow.add_node(\"retrieve_schema_node\", retrieve_schema_node)\nworkflow.add_node(\"query_gen_node\", query_gen_node)\nworkflow.add_node(\"correct_query_node\", correct_query_node)\nworkflow.add_node(\"execute_query_node\", execute_query_node)\n\n# Add edges with updated node names\nworkflow.add_edge(START, \"initial_tool_node\")\nworkflow.add_edge(\"initial_tool_node\", \"list_tables_node\")\nworkflow.add_edge(\"list_tables_node\", \"model_get_schema_node\")\nworkflow.add_edge(\"model_get_schema_node\", \"retrieve_schema_node\")\nworkflow.add_edge(\"retrieve_schema_node\", \"query_gen_node\")\nworkflow.add_conditional_edges(\"query_gen_node\", should_continue, [END, \"correct_query_node\", \"query_gen_node\"])\nworkflow.add_edge(\"correct_query_node\", \"execute_query_node\")\nworkflow.add_edge(\"execute_query_node\", \"query_gen_node\")\n\napp = workflow.compile()\n\n# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:31.992363Z","iopub.execute_input":"2025-01-13T11:25:31.992746Z","iopub.status.idle":"2025-01-13T11:25:32.108697Z","shell.execute_reply.started":"2025-01-13T11:25:31.99272Z","shell.execute_reply":"2025-01-13T11:25:32.107484Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Helper Functions for Query Execution\n\nWe define helper functions to extract, execute, and format SQL queries and their results.\n\n### Key Workflow:\n\n- The code is designed to work with a workflow that generates SQL queries from natural language questions.\n- It extracts the query, executes it on the database, and formats the results for easy interpretation.\n- Error handling is included to ensure robustness during query execution and result formatting.\n\nThis set of functions is typically used in conjunction with a larger system (like the one in the notebook) to automate SQL query generation and execution based on user input.","metadata":{}},{"cell_type":"code","source":"from openai import BadRequestError\n\ndef extract_sql_query(final_answer: str) -> str:\n    \"\"\"\n    Extracts the SQL query from the final_answer string.\n    \n    Args:\n        final_answer (str): The final answer string that may contain an SQL query.\n    \n    Returns:\n        str: The extracted SQL query if found, otherwise None.\n    \"\"\"\n    if \"```sql\" in final_answer:\n        return final_answer.split(\"```sql\")[1].split(\"```\")[0].strip()\n    return None\n\ndef execute_sql_query(sql_query: str):\n    \"\"\"\n    Executes the SQL query and returns the results.\n    \n    Args:\n        sql_query (str): The SQL query to execute.\n    \n    Returns:\n        Any: The results of the SQL query execution, or None if an error occurs.\n    \"\"\"\n    try:\n        results = db.run(sql_query)\n        return results\n    except Exception as e:\n        print(\"Error executing SQL query:\", e)\n        return None\n\ndef format_results(results) -> str:\n    \"\"\"\n    Formats the query results into a human-readable string.\n    \n    Args:\n        results (Any): The results of the SQL query execution.\n    \n    Returns:\n        str: A formatted string representing the query results.\n    \"\"\"\n    if isinstance(results, str):\n        # If results is a string, return it as-is\n        return results\n\n    formatted_results = \"The total sales amount per country is:\\n\"\n    try:\n        for row in results:\n            # Handle cases where row is a tuple or list\n            if isinstance(row, (tuple, list)) and len(row) >= 2:\n                formatted_results += f\"- {row[0]}: ${row[1]:.2f}\\n\"\n            else:\n                # Handle unexpected row formats\n                formatted_results += f\"- {row}\\n\"\n    except Exception as e:\n        print(\"Error formatting results:\", e)\n        return str(results)  # Fallback: return results as a string\n\n    return formatted_results\n\ndef process_event(event):\n    \"\"\"\n    Processes the event to extract, execute, and print the final answer.\n    \n    Args:\n        event (dict): The event containing the state of the workflow.\n    \"\"\"\n    if \"query_gen_node\" not in event:\n        return\n\n    query_gen_state = event[\"query_gen_node\"]\n    if \"messages\" not in query_gen_state:\n        return\n\n    last_message = query_gen_state[\"messages\"][-1]\n    if not hasattr(last_message, \"tool_calls\") or not last_message.tool_calls:\n        return\n\n    final_answer = last_message.tool_calls[0][\"args\"][\"final_answer\"]\n    sql_query = extract_sql_query(final_answer)\n\n    if not sql_query:\n        print(\"No SQL query found in the final answer. The agent provided the following response:\")\n        print(final_answer)\n        return\n\n    print(f\"Extracted SQL Query:\\n{sql_query}\\n\")\n    results = execute_sql_query(sql_query)\n\n    if results:\n        formatted_results = format_results(results)\n        print(\"Final Answer:\", formatted_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:32.109709Z","iopub.execute_input":"2025-01-13T11:25:32.110011Z","iopub.status.idle":"2025-01-13T11:25:32.120401Z","shell.execute_reply.started":"2025-01-13T11:25:32.109987Z","shell.execute_reply":"2025-01-13T11:25:32.119191Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Execute Queries Based on User Questions\n\nFinally, we execute the workflow for different user questions and print the results.","metadata":{}},{"cell_type":"code","source":"try:\n    question = \"What is the total sales amount per country?\"\n    for event in app.stream({\"messages\": [(\"user\", question)]}):\n        process_event(event)\nexcept BadRequestError as e:\n    print(f\"Error processing question: {question}\")\n    print(f\"Error details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:32.12117Z","iopub.execute_input":"2025-01-13T11:25:32.121434Z","iopub.status.idle":"2025-01-13T11:25:33.990788Z","shell.execute_reply.started":"2025-01-13T11:25:32.121411Z","shell.execute_reply":"2025-01-13T11:25:33.989781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    question = \"What is the total sales amount per genre?\"\n    for event in app.stream({\"messages\": [(\"user\", question)]}):\n        process_event(event)\nexcept BadRequestError as e:\n    print(f\"Error processing question: {question}\")\n    print(f\"Error details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:33.991739Z","iopub.execute_input":"2025-01-13T11:25:33.992019Z","iopub.status.idle":"2025-01-13T11:25:35.34418Z","shell.execute_reply.started":"2025-01-13T11:25:33.991996Z","shell.execute_reply":"2025-01-13T11:25:35.34303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    question = \"How many tracks are in each playlist?\"\n    for event in app.stream({\"messages\": [(\"user\", question)]}):\n        process_event(event)\nexcept BadRequestError as e:\n    print(f\"Error processing question: {question}\")\n    print(f\"Error details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:35.345125Z","iopub.execute_input":"2025-01-13T11:25:35.345398Z","iopub.status.idle":"2025-01-13T11:25:36.431971Z","shell.execute_reply.started":"2025-01-13T11:25:35.345375Z","shell.execute_reply":"2025-01-13T11:25:36.430856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    question = \"Which 5 artists have the most tracks in the database?\"\n    for event in app.stream({\"messages\": [(\"user\", question)]}):\n        process_event(event)\nexcept BadRequestError as e:\n    print(f\"Error processing question: {question}\")\n    print(f\"Error details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:36.432933Z","iopub.execute_input":"2025-01-13T11:25:36.433217Z","iopub.status.idle":"2025-01-13T11:25:37.611028Z","shell.execute_reply.started":"2025-01-13T11:25:36.433193Z","shell.execute_reply":"2025-01-13T11:25:37.609789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    question = \"Who are the top 3 customers by total spending?\"\n    for event in app.stream({\"messages\": [(\"user\", question)]}):\n        process_event(event)\nexcept BadRequestError as e:\n    print(f\"Error processing question: {question}\")\n    print(f\"Error details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:25:37.612045Z","iopub.execute_input":"2025-01-13T11:25:37.612412Z","iopub.status.idle":"2025-01-13T11:25:38.975328Z","shell.execute_reply.started":"2025-01-13T11:25:37.612385Z","shell.execute_reply":"2025-01-13T11:25:38.974404Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nThis notebook demonstrates a powerful workflow for generating and executing SQL queries based on natural language questions. By leveraging LangChain, OpenAI, and SQLDatabaseToolkit, we can create a robust system that handles complex queries, corrects common mistakes, and formats results for easy interpretation. This approach can be extended to various other use cases, making it a valuable tool for data analysis and database management.\n\nThis workflow can be applied to various real-world scenarios, such as:\n- **Business Intelligence**: Automating the generation of reports and insights from databases.\n- **Data Exploration**: Enabling non-technical users to query databases using natural language.\n- **Customer Support**: Providing automated answers to customer queries based on database data.\n- **Education**: Teaching SQL concepts by translating natural language questions into queries.","metadata":{}}]}