{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Automating Data Analysis with PythonREPLTool and LLMs**\n\n## **Introduction**\n\nIn today’s data-driven world, businesses and individuals alike rely heavily on data analysis to make informed decisions. However, the process of analyzing data—loading datasets, performing calculations, and generating visualizations—can often be time-consuming and require specialized skills. Enter **large language models (LLMs)** like OpenAI’s GPT-4, which have revolutionized how we interact with technology. By combining the natural language understanding of LLMs with custom tools, we can automate complex workflows and make data analysis more accessible to everyone.\n\nThis example demonstrates how to use **LangChain**, a powerful framework for building LLM-powered applications, to create a conversational data analysis assistant. The assistant will handle a complete data analysis task: loading a CSV file containing sales data, calculating the total sales for each product, generating a bar plot to visualize the results, and providing a final summary—all through a simple conversational interface. By integrating LangChain with custom Python tools, we can bridge the gap between natural language and data analysis, enabling users to interact with data in a more intuitive and efficient way.\n\nThe workflow is designed to be flexible and scalable, making it suitable for a wide range of data analysis tasks. Whether you’re a business analyst looking to automate repetitive tasks or a developer exploring the potential of LLMs, this example provides a practical foundation for building intelligent, tool-enhanced conversational agents. Let’s dive into the step-by-step process of creating this assistant and see how it can transform the way we work with data.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\nThis section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, Anthropic models, DuckDuckGo search, and other utilities. These libraries include:\n- `langchain-openai`: Provides integration with OpenAI's embedding models and APIs.\n- `langchain-anthropic`: Enables integration with Anthropic's models and APIs.\n- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n- `langgraph`: A library for building and visualizing graph-based workflows in LangChain.\n- `duckduckgo-search`: Enables programmatic access to DuckDuckGo's search functionality.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU duckduckgo-search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:06:52.906984Z","iopub.execute_input":"2025-01-22T17:06:52.907317Z","iopub.status.idle":"2025-01-22T17:07:32.996924Z","shell.execute_reply.started":"2025-01-22T17:06:52.907288Z","shell.execute_reply":"2025-01-22T17:07:32.995535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Create a CSV File with Sales Data**\nThis block creates a CSV file named `sales_data.csv` containing sales data for three products over five days.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Define the data\ndata = {\n    \"Date\": [\n        \"2023-10-01\", \"2023-10-01\", \"2023-10-01\",\n        \"2023-10-02\", \"2023-10-02\", \"2023-10-02\",\n        \"2023-10-03\", \"2023-10-03\", \"2023-10-03\",\n        \"2023-10-04\", \"2023-10-04\", \"2023-10-04\",\n        \"2023-10-05\", \"2023-10-05\", \"2023-10-05\",\n    ],\n    \"Product\": [\n        \"Product A\", \"Product B\", \"Product C\",\n        \"Product A\", \"Product B\", \"Product C\",\n        \"Product A\", \"Product B\", \"Product C\",\n        \"Product A\", \"Product B\", \"Product C\",\n        \"Product A\", \"Product B\", \"Product C\",\n    ],\n    \"Sales\": [\n        1000, 500, 1500,\n        1200, 600, 1800,\n        900, 400, 1300,\n        1100, 550, 1600,\n        1300, 700, 2000,\n    ],\n}\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to a CSV file\ndf.to_csv(\"sales_data.csv\", index=False)\n\nprint(\"sales_data.csv created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:08:35.740983Z","iopub.execute_input":"2025-01-22T17:08:35.741485Z","iopub.status.idle":"2025-01-22T17:08:36.181861Z","shell.execute_reply.started":"2025-01-22T17:08:35.741441Z","shell.execute_reply":"2025-01-22T17:08:36.18079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 1: Define Custom Tools**\nDefine custom tools for data analysis using the `@tool` decorator. These tools will handle specific tasks like loading CSV files and generating plots.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_experimental.tools.python.tool import PythonREPLTool\nfrom langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\nfrom langchain_core.tools import tool\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n@tool\ndef csv_loader(file_path: str) -> str:\n    \"\"\"Load a CSV file into a pandas DataFrame and return it as JSON.\"\"\"\n    return pd.read_csv(file_path).to_json(orient=\"split\")  # Use \"split\" orientation for better compatibility\n\n@tool\ndef plot(data_json: str, plot_type: str, x: str, y: str) -> str:\n    \"\"\"Generate a plot from a pandas DataFrame and save it as an image.\"\"\"\n    try:\n        df = pd.read_json(data_json, orient=\"split\")  # Use \"split\" orientation for better compatibility\n        if plot_type == \"line\":\n            df.plot(x=x, y=y, kind=\"line\")\n        elif plot_type == \"bar\":\n            df.plot(x=x, y=y, kind=\"bar\")\n        plt.savefig(\"plot.png\")\n        return \"Plot saved as plot.png\"\n    except Exception as e:\n        return f\"Error generating plot: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.531102Z","iopub.execute_input":"2025-01-22T17:12:21.531537Z","iopub.status.idle":"2025-01-22T17:12:21.553717Z","shell.execute_reply.started":"2025-01-22T17:12:21.531503Z","shell.execute_reply":"2025-01-22T17:12:21.552368Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 2: Initialize the LLM**\nInitialize the `ChatOpenAI` model with the `gpt-4o-mini` model and set the temperature to `0` for deterministic responses. Fetch the API key securely using `kaggle_secrets`.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_anthropic import ChatAnthropic\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=user_secrets.get_secret(\"my-openai-api-key\"))\n#model = ChatAnthropic(model=\"claude-3-5-latest\", temperature=0, api_key=user_secrets.get_secret(\"my-anthropic-api-key\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.555329Z","iopub.execute_input":"2025-01-22T17:12:21.555839Z","iopub.status.idle":"2025-01-22T17:12:21.893445Z","shell.execute_reply.started":"2025-01-22T17:12:21.55579Z","shell.execute_reply":"2025-01-22T17:12:21.892384Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 3: Initialize the Tools**\nInitialize the tools, including the built-in `PythonREPLTool` and the custom tools (`csv_loader` and `plot`).","metadata":{}},{"cell_type":"code","source":"from langchain_experimental.tools.python.tool import PythonREPLTool\n\npython_tool = PythonREPLTool()\ncsv_loader_tool = csv_loader\nplot_tool = plot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.895811Z","iopub.execute_input":"2025-01-22T17:12:21.896172Z","iopub.status.idle":"2025-01-22T17:12:21.900863Z","shell.execute_reply.started":"2025-01-22T17:12:21.89614Z","shell.execute_reply":"2025-01-22T17:12:21.899806Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 4: Bind the Tools to the LLM**\nBind the tools to the `ChatOpenAI` model using the `bind_tools()` method. This allows the model to dynamically invoke these tools based on the user's request.","metadata":{}},{"cell_type":"code","source":"model_with_tools = model.bind_tools([python_tool, csv_loader_tool, plot_tool])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.902763Z","iopub.execute_input":"2025-01-22T17:12:21.903146Z","iopub.status.idle":"2025-01-22T17:12:21.939502Z","shell.execute_reply.started":"2025-01-22T17:12:21.903117Z","shell.execute_reply":"2025-01-22T17:12:21.938241Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 5: Define the User Prompt**\nDefine the user prompt, which requests the assistant to:\n1. Load a CSV file.\n2. Calculate total sales for each product.\n3. Generate a bar plot of total sales by product.\n4. Display the total sales and the plot.","metadata":{}},{"cell_type":"code","source":"user_prompt = \"\"\"\nI have a CSV file named 'sales_data.csv' with columns: 'Date', 'Product', 'Sales'.\n1. Load the CSV file.\n2. Calculate the total sales for each product.\n3. Generate a bar plot of total sales by product.\n4. Tell me the total sales for each product and show the plot.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.940835Z","iopub.execute_input":"2025-01-22T17:12:21.9412Z","iopub.status.idle":"2025-01-22T17:12:21.951907Z","shell.execute_reply.started":"2025-01-22T17:12:21.941166Z","shell.execute_reply":"2025-01-22T17:12:21.949758Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 6: Create a Conversation History**\nCreate a conversation history with a `SystemMessage` to set the assistant's role and a `HumanMessage` containing the user's prompt.","metadata":{}},{"cell_type":"code","source":"from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n\nmessages = [\n    SystemMessage(content=\"You are a helpful data analysis assistant.\"),\n    HumanMessage(content=user_prompt),\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.95347Z","iopub.execute_input":"2025-01-22T17:12:21.95382Z","iopub.status.idle":"2025-01-22T17:12:21.980794Z","shell.execute_reply.started":"2025-01-22T17:12:21.953787Z","shell.execute_reply":"2025-01-22T17:12:21.979592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 7: Process Tool Calls Iteratively**\nProcess tool calls iteratively until the LLM generates a final response. This involves:\n1. Sending the conversation history to the LLM.\n2. Checking for tool calls in the response.\n3. Invoking the appropriate tool and updating the conversation history.\n4. Breaking the loop when no more tool calls are generated.","metadata":{}},{"cell_type":"code","source":"max_iterations = 5  # Prevent infinite loops\nfor _ in range(max_iterations):\n    response = model_with_tools.invoke(messages)\n\n    # Check if the response contains tool calls\n    if not response.additional_kwargs.get(\"tool_calls\"):\n        # No more tool calls, break the loop\n        break\n\n    # Process tool calls\n    print(\"Processing tool calls...\")  # Debug message\n    for tool_call in response.additional_kwargs.get(\"tool_calls\", []):\n        tool_name = tool_call[\"function\"][\"name\"]\n        tool_args = eval(tool_call[\"function\"][\"arguments\"])\n\n        if tool_name == \"csv_loader\":\n            # Load the CSV file\n            tool_result = csv_loader_tool.invoke(tool_args[\"file_path\"])\n            messages.append(AIMessage(content=\"\", additional_kwargs={\"tool_calls\": [tool_call]}))\n            messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))\n\n        elif tool_name == \"Python_REPL\":\n            # Execute Python code (e.g., calculate total sales)\n            tool_result = python_tool.run(tool_args[\"query\"])\n            messages.append(AIMessage(content=\"\", additional_kwargs={\"tool_calls\": [tool_call]}))\n            messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))\n\n        elif tool_name == \"plot\":\n            # Generate a plot\n            tool_result = plot_tool.invoke(tool_args)  # Pass tool_args as input\n            messages.append(AIMessage(content=\"\", additional_kwargs={\"tool_calls\": [tool_call]}))\n            messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:21.982076Z","iopub.execute_input":"2025-01-22T17:12:21.98241Z","iopub.status.idle":"2025-01-22T17:12:41.229524Z","shell.execute_reply.started":"2025-01-22T17:12:21.982371Z","shell.execute_reply":"2025-01-22T17:12:41.228439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Step 8: Print the Final Response**\nPrint the final response from the LLM, which includes the total sales for each product and a confirmation that the plot has been saved.","metadata":{}},{"cell_type":"code","source":"print(\"Final Answer:\\n\", response.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T17:12:41.230608Z","iopub.execute_input":"2025-01-22T17:12:41.230913Z","iopub.status.idle":"2025-01-22T17:12:41.236642Z","shell.execute_reply.started":"2025-01-22T17:12:41.230887Z","shell.execute_reply":"2025-01-22T17:12:41.235534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Conclusion**\n\nThis example highlights the transformative potential of integrating large language models with custom tools to automate and simplify data analysis tasks. By leveraging LangChain, we’ve built a conversational assistant that can dynamically load data, perform calculations, and generate visualizations—all through natural language interactions. The workflow is not only efficient but also highly adaptable, allowing it to be extended to more complex tasks or integrated into larger systems.\n\nThe ability to interact with data using natural language opens up new possibilities for accessibility and productivity. Users no longer need to write complex code or navigate specialized software to analyze data; instead, they can simply describe their needs in plain English and let the assistant handle the rest. As LLMs continue to evolve, their integration with domain-specific tools will unlock even more opportunities for innovation, making advanced data analysis capabilities available to a broader audience.\n\nWhether you’re analyzing sales data, visualizing trends, or automating repetitive tasks, this approach provides a powerful and user-friendly way to interact with data. By combining the strengths of LLMs and custom tools, we can create intelligent systems that empower users to make data-driven decisions with ease. The future of data analysis is conversational, and this example is just the beginning.","metadata":{}}]}