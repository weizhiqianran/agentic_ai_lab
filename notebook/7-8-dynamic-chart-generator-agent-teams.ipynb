{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi-Agent Network Architecture for Complex Tasks\n\n## Introduction\n\nIn this tutorial, we explore a powerful approach to handling complex tasks by leveraging a **multi-agent network architecture**. The core idea is to use a \"divide-and-conquer\" strategy, where specialized agents are created for specific tasks or domains, and tasks are routed to the appropriate \"expert\" agent. This approach allows for efficient problem-solving by breaking down complex tasks into smaller, manageable subtasks, each handled by an agent with the right expertise.\n\nThis tutorial demonstrates how to implement such a system using **LangGraph**, a framework for building multi-agent workflows. We will define specialized agents, such as a research agent for retrieving data and a chart generator agent for creating visualizations, and connect them in a collaborative network. By the end of this tutorial, you will understand how to design and deploy a multi-agent system to tackle complex, real-world problems effectively.","metadata":{}},{"cell_type":"markdown","source":"## Installation and Setup\n\nBefore we begin, we need to install the necessary libraries. These include LangChain, LangGraph, and other dependencies required for the agents to function.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU duckduckgo_search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T15:39:40.788364Z","iopub.execute_input":"2025-01-13T15:39:40.788766Z","iopub.status.idle":"2025-01-13T15:40:23.812873Z","shell.execute_reply.started":"2025-01-13T15:39:40.788717Z","shell.execute_reply":"2025-01-13T15:40:23.811317Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining Tools and Agents\n\nIn this section, we define the tools and agents that will be used in the multi-agent network. The tools include a DuckDuckGo search tool and a Python REPL tool for executing code. We also define the system prompts for the agents.\n\nThe code begins by importing necessary libraries, including `DuckDuckGoSearchRun` for web searches and `PythonREPL` for executing Python code. Two tools are then defined:\n\n1. **DuckDuckGo Search Tool**:\n   - This tool performs web searches using DuckDuckGo.\n   - It takes a `query` and an optional `max_results` parameter (defaulting to 5) and returns the search results as a string.\n\n2. **Python REPL Tool**:\n   - This tool executes Python code locally using a Python REPL.\n   - It takes a `code` string as input, executes it, and returns the result or an error message if execution fails.\n   - A warning is included to highlight that executing code locally can be unsafe if not sandboxed properly.\n\nAdditionally, the `make_system_prompt` function generates a system prompt for the AI assistants. This prompt provides context for collaboration, instructs the assistants to use the provided tools, and specifies that they should prefix their response with `\"FINAL ANSWER\"` when the task is complete. The function appends additional instructions (`suffix`) to the base prompt for customization.\n\nThese tools and prompts form the foundation for the multi-agent network, enabling agents to retrieve data and execute code while collaborating effectively.","metadata":{}},{"cell_type":"code","source":"from typing import Annotated\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_core.tools import tool\nfrom langchain_experimental.utilities import PythonREPL\n\n# Define DuckDuckGo Search Tool\n@tool\ndef duckduckgo_search(query: str, max_results: int = 5) -> str:\n    \"\"\"Perform a search using DuckDuckGo and return the results.\n    \n    Args:\n        query (str): The search query to be executed.\n        max_results (int, optional): The maximum number of results to return. Defaults to 5.\n    \n    Returns:\n        str: The search results as a string.\n    \"\"\"\n    search = DuckDuckGoSearchRun()  # Initialize DuckDuckGoSearchRun\n    results = search.run(query)     # Use run method for search\n    return str(results)\n\n# Warning: This executes code locally, which can be unsafe when not sandboxed\nrepl = PythonREPL()\n\n@tool\ndef python_repl_tool(code: Annotated[str, \"The python code to execute to generate your chart.\"]):\n    \"\"\"Execute Python code using a Python REPL (Read-Eval-Print Loop).\n    \n    Args:\n        code (str): The Python code to execute.\n    \n    Returns:\n        str: The result of the executed code or an error message if execution fails.\n    \"\"\"\n    try:\n        result = repl.run(code)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n    return (\n        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n    )\n\n# Create graph and define agent nodes\ndef make_system_prompt(suffix: str) -> str:\n    \"\"\"Generate a system prompt for the AI assistant.\n    \n    Args:\n        suffix (str): Additional context or instructions to append to the base system prompt.\n    \n    Returns:\n        str: The complete system prompt.\n    \"\"\"\n    return (\n        \"You are a helpful AI assistant, collaborating with other assistants.\"\n        \" Use the provided tools to progress towards answering the question.\"\n        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n        \" will help where you left off. Execute what you can to make progress.\"\n        \" If you or any of the other assistants have the final answer or deliverable,\"\n        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n        f\"\\n{suffix}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T15:41:31.895371Z","iopub.execute_input":"2025-01-13T15:41:31.895814Z","iopub.status.idle":"2025-01-13T15:41:33.231407Z","shell.execute_reply.started":"2025-01-13T15:41:31.895783Z","shell.execute_reply":"2025-01-13T15:41:33.230292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating the Multi-Agent Network\n\nIn this section, we create the multi-agent network using LangGraph. We define the research agent and the chart generator agent, and then we create the graph that connects these agents.\n\nThe code begins by importing necessary libraries, including `langchain_core.messages` for message handling, `langchain_openai` and `langchain_anthropic` for language models, and `langgraph` for building the multi-agent graph. The Anthropic API key is loaded to authenticate the language model (`claude-3-5-sonnet-latest`), which powers the agents.\n\nNext, we define the logic for transitioning between nodes using the `get_next_node` function. This function checks if the last message contains `\"FINAL ANSWER\"` to determine whether to terminate the graph or proceed to the next node.\n\nThe **research agent** is then created, specializing in retrieving data using the DuckDuckGo search tool. It is given a specific task (`research_task`) and a system prompt to focus solely on research. The `research_node` function executes this agent, processes the search results, and transitions to the `chart_node` for further processing.\n\nThe **chart generator agent** is responsible for creating visualizations using the Python REPL tool. It follows detailed instructions (`chart_task`) to generate clear, visually appealing charts using libraries like `seaborn` and `plotly`. The `chart_node` function executes this agent, processes the chart generation, and transitions back to the `research_node` if additional research is needed.\n\nFinally, the graph is constructed using `StateGraph` with `MessagesState` to manage the conversation state. Two nodes are added: `research_node` for data retrieval and `chart_node` for chart generation. The graph starts at the `research_node` and transitions to the `chart_node` after research is completed. The graph is then compiled into an executable workflow. Optionally, the graph can be visualized using Mermaid.js, though this step requires additional dependencies.\n\nThis modular approach enables efficient handling of complex tasks by leveraging specialized agents that collaborate within a structured workflow.","metadata":{}},{"cell_type":"code","source":"from typing import Literal\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain_anthropic import ChatAnthropic\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph.graph import MessagesState, END\nfrom langgraph.types import Command\nfrom kaggle_secrets import UserSecretsClient\n\n# Load Anthropic API Key\nmy_api_key = UserSecretsClient().get_secret(\"my-anthropic-api-key\")\n\n#llm = ChatOpenAI(model=\"gpt-o1-mini\", api_key=my_api_key)\nllm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\", api_key=my_api_key)\n\ndef get_next_node(last_message: BaseMessage, goto: str):\n    \"\"\"Determine the next node to transition to based on the last message.\n    \n    Args:\n        last_message (BaseMessage): The last message in the conversation.\n        goto (str): The default node to transition to if no final answer is found.\n    \n    Returns:\n        str: The next node to transition to, or END if a final answer is found.\n    \"\"\"\n    if \"FINAL ANSWER\" in last_message.content:\n        return END\n    return goto\n\n# Research agent and node\nresearch_task = \"You can only do research. You are working with a chart generator colleague.\"\nresearch_agent = create_react_agent(llm, tools=[duckduckgo_search], state_modifier=make_system_prompt(research_task))\n\ndef research_node(state: MessagesState) -> Command[Literal[\"chart_node\", END]]:\n    \"\"\"Execute the research node, which performs research using the DuckDuckGo search tool.\n    \n    Args:\n        state (MessagesState): The current state of the conversation.\n    \n    Returns:\n        Command: A command object containing the updated state and the next node to transition to.\n    \"\"\"\n    result = research_agent.invoke(state)\n    goto = get_next_node(result[\"messages\"][-1], \"chart_node\")\n    result[\"messages\"][-1] = HumanMessage(\n        content=result[\"messages\"][-1].content, name=\"research_node\"\n    )\n    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n\n# Chart generator agent and node\nchart_task = \"\"\"Create clear and visually appealing charts using seaborn and plotly. Follow these rules:\n1. Add a title, labeled axes (with units), and a legend if needed.\n2. Use `sns.set_context(\"notebook\")` for readable text and themes like `sns.set_theme()` or `sns.set_style(\"whitegrid\")`.\n3. Use accessible color palettes like `sns.color_palette(\"husl\")`.\n4. Choose appropriate plots: `sns.lineplot()`, `sns.barplot()`, or `sns.heatmap()`.\n5. Annotate key points (e.g., \"Peak in 2020\") for clarity.\n6. Ensure the chart's width and display resolution is no wider than 1000px.\n7. Display with `plt.show()`.\nGoal: Produce accurate, engaging, and easy-to-interpret charts.\"\"\"\nchart_agent = create_react_agent(llm, [python_repl_tool], state_modifier=make_system_prompt(chart_task))\n\ndef chart_node(state: MessagesState) -> Command[Literal[\"research_node\", END]]:\n    \"\"\"Execute the chart node, which generates charts using the Python REPL tool.\n    \n    Args:\n        state (MessagesState): The current state of the conversation.\n    \n    Returns:\n        Command: A command object containing the updated state and the next node to transition to.\n    \"\"\"\n    result = chart_agent.invoke(state)\n    goto = get_next_node(result[\"messages\"][-1], \"research_node\")\n    result[\"messages\"][-1] = HumanMessage(\n        content=result[\"messages\"][-1].content, name=\"chart_node\"\n    )\n    return Command(update={\"messages\": result[\"messages\"]}, goto=goto)\n\n# Define the graph\nfrom langgraph.graph import StateGraph, START\n\nworkflow = StateGraph(MessagesState)\nworkflow.add_node(\"research_node\", research_node)\nworkflow.add_node(\"chart_node\", chart_node)\n\nworkflow.add_edge(START, \"research_node\")\ngraph = workflow.compile()\n\nfrom IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T15:41:33.232879Z","iopub.execute_input":"2025-01-13T15:41:33.233422Z","iopub.status.idle":"2025-01-13T15:41:35.196274Z","shell.execute_reply.started":"2025-01-13T15:41:33.233381Z","shell.execute_reply":"2025-01-13T15:41:35.194842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pretty-Printing Event Messages for Debugging\n\nThe `print_pretty` function is designed to format and display messages from events in a readable and structured way, making it easier to debug or log the interactions within the multi-agent network. Here's how it works:\n\n1. **Input**: The function takes an `event` dictionary as input, which contains messages generated by the agents (e.g., `research_node` or `chart_node`).\n2. **Node Key Check**: It checks if the event contains messages from specific nodes (`research_node` or `chart_node`). If found, it proceeds to process the messages.\n3. **Message Extraction**:\n   - For each message in the event, it extracts the message type (e.g., `HumanMessage`, `AIMessage`) using `message.__class__.__name__`.\n   - The `content` of the message is extracted and formatted. If the content is a list, it is processed as a list of items. If it is a string, it is wrapped in quotes for better readability.\n4. **Additional Fields**:\n   - The function also extracts and prints additional metadata such as `additional_kwargs`, `response_metadata`, and `message.id` to provide more context about the message.\n5. **Formatted Output**:\n   - Each message is printed in a structured format, showing its type, content, metadata, and ID.\n   - The output is indented and formatted for clarity, making it easy to read and analyze.\n6. **Separator**:\n   - A separator line (`\"-\" * 120`) is printed after each node's messages to visually distinguish between different nodes.\n7. **Fallback**:\n   - If no messages are found in the event, the function prints \"No messages found in the event.\"","metadata":{}},{"cell_type":"code","source":"def print_pretty(event):\n    \"\"\"Pretty-print the event messages for debugging or logging purposes.\n    \n    Args:\n        event (dict): The event containing messages from the research or chart node.\n    \"\"\"\n    # Check if the event contains 'research_node' or 'chart_node'\n    for node_key in [\"research_node\", \"chart_node\"]:\n        if node_key in event:\n            messages = event[node_key].get(\"messages\", [])\n            print(f\"{node_key}: [\")\n            for message in messages:\n                # Extract message type (HumanMessage, AIMessage, etc.)\n                message_type = message.__class__.__name__\n\n                # Extract message content\n                content = message.content\n                if isinstance(content, list):\n                    content = [item for item in content]  # Handle list content (e.g., AIMessage with tool use)\n                elif isinstance(content, str):\n                    content = f'\"{content}\"'  # Wrap string content in quotes\n\n                # Extract additional fields\n                additional_kwargs = message.additional_kwargs\n                response_metadata = message.response_metadata\n                message_id = message.id\n\n                # Print the message in the desired format\n                print(f\"    {message_type}(\")\n                print(f\"        content={content},\")\n                print(f\"        additional_kwargs={additional_kwargs},\")\n                print(f\"        response_metadata={response_metadata},\")\n                print(f\"        id='{message_id}'\")\n                print( \"    ),\")\n            print(\"]\")\n            print(\"-\" * 120)\n            return\n\n    print(\"No messages found in the event.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T15:47:00.922581Z","iopub.execute_input":"2025-01-13T15:47:00.923053Z","iopub.status.idle":"2025-01-13T15:47:00.930714Z","shell.execute_reply.started":"2025-01-13T15:47:00.923012Z","shell.execute_reply":"2025-01-13T15:47:00.929507Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Example 1: USA Population Growth Over Time\n\nIn this example, we use the multi-agent network to retrieve USA population data for the past 50 years and generate a line chart with annotations for significant events like economic recessions.","metadata":{}},{"cell_type":"code","source":"# Invoke the graph\nevents = graph.stream(\n    {\n        \"messages\": [\n            HumanMessage(\n                content=\"First, get the USA's population data for the past 50 years. \"\n                \"Then, create a line chart with annotations for significant events like economic recessions. \"\n                \"Add a trendline using numpy.polyfit. \"\n                \"Once you make the chart, finish.\"\n            )\n        ],\n    },\n    {\"recursion_limit\": 150},\n)\n\n# Print events using print_pretty\nfor event in events:\n    print_pretty(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T15:47:05.518167Z","iopub.execute_input":"2025-01-13T15:47:05.518533Z","iopub.status.idle":"2025-01-13T15:47:34.056703Z","shell.execute_reply.started":"2025-01-13T15:47:05.518507Z","shell.execute_reply":"2025-01-13T15:47:34.05548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Example 2: Global CO2 Emissions by Country\n\nIn this example, we retrieve CO2 emissions data for the top 10 emitting countries over the past 20 years and create an interactive stacked area chart using Plotly.","metadata":{}},{"cell_type":"code","source":"# Invoke the graph\nprompt_message = (\"\"\"First, retrieve CO2 emissions data for the top 10 emitting countries over the past 20 years. \nThen, create a stacked area chart using Seaborn. \nHighlight the country with the highest emissions each year by making its line thicker and adding annotations. \nEnsure the chart includes a title, labeled axes, and a legend. \nUse a custom color palette for better visualization. \nOnce the chart is created, display it with `plt.show()` and ensure the width is no wider than 1000px.\"\"\")\n\n# Invoke the graph\nevents = graph.stream(\n    {\n        \"messages\": [\n            HumanMessage(\n                content=prompt_message\n            )\n        ],\n    },\n    {\"recursion_limit\": 150},\n)\n\n# Print events using print_pretty\nfor event in events:\n    print_pretty(event)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Example 3: Weather Data Visualization\n\nIn this example, we retrieve temperature and precipitation data for New York City over the past 5 years and create a dual-axis chart with shaded regions for extreme weather events.","metadata":{}},{"cell_type":"code","source":"# Invoke the graph\nevents = graph.stream(\n    {\n        \"messages\": [\n            HumanMessage(\n                content=\"First, get temperature and precipitation data for New York City over the past 5 years. \"\n                \"Then, create a dual-axis chart with temperature on the left y-axis and precipitation on the right y-axis. \"\n                \"Add shaded regions for extreme weather events like heatwaves and heavy rainfall. \"\n                \"Once you make the chart, finish.\"\n            )\n        ],\n    },\n    {\"recursion_limit\": 150},\n)\n\n# Print events using print_pretty\nfor event in events:\n    print_pretty(event)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nThis notebook demonstrates how to implement a `Multi-Agent Network Architecture` using `LangGraph`. By dividing tasks among specialized agents, we can effectively handle complex tasks that require multiple domains of expertise. This approach is highly flexible and can be adapted to various use cases, from data retrieval to visualization.","metadata":{}}]}