{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **From Planning to Execution: Building Intelligent Agents with LangGraph**\n\n## Introduction\n\nThe provided example demonstrates a **multi-step task execution workflow** using LangChain and LangGraph. The workflow is designed to handle complex queries by breaking them down into smaller, manageable steps, executing them sequentially, and dynamically re-planning as needed. This approach ensures that the agent can handle tasks that require multiple steps, such as searching for information, processing results, and providing a final response.\n\n### Key Steps in the Workflow:\n1. **Initialize the LLM**: The workflow begins by initializing a language model (LLM) using either OpenAI's GPT-4 or Anthropic's Claude-3. The API key is securely fetched using `kaggle_secrets`.\n2. **Define Tools and Custom Prompt**: The workflow defines the tools (e.g., `DuckDuckGoSearchRun`) and a custom prompt to guide the agent's behavior.\n3. **Define the State and Planning Logic**: The state structure (`PlanExecute`) is defined to track the input, plan, past steps, and final response. The `planner` generates a step-by-step plan to achieve the objective.\n4. **Define Re-Planning Logic**: The `replanner` updates the plan based on the results of previous steps. If no further steps are needed, it returns the final response.\n5. **Create the Graph and Define Nodes**: The workflow graph is created, with nodes for planning (`plan_node`), execution (`agent_node`), and re-planning (`replan_node`). The graph orchestrates the execution of tasks and ensures the workflow terminates when the final response is ready.\n6. **Execute the Workflow**: The workflow is executed with a sample input, and the agent processes the query step by step, providing the final result.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\nThis section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, Anthropic models, DuckDuckGo search, and other utilities. These libraries include:\n- `langchain-openai`: Provides integration with OpenAI's embedding models and APIs.\n- `langchain-anthropic`: Enables integration with Anthropic's models and APIs.\n- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n- `langgraph`: A library for building and visualizing graph-based workflows in LangChain.\n- `duckduckgo-search`: Enables programmatic access to DuckDuckGo's search functionality.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU duckduckgo-search","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:41:27.131402Z","iopub.execute_input":"2025-01-23T18:41:27.131759Z","iopub.status.idle":"2025-01-23T18:42:03.487864Z","shell.execute_reply.started":"2025-01-23T18:41:27.13173Z","shell.execute_reply":"2025-01-23T18:42:03.486615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Initialize LLM with API Key\nThis step initializes the language model (LLM) using either OpenAI's GPT-4 or Anthropic's Claude-3. The API key is securely fetched using `kaggle_secrets`.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_anthropic import ChatAnthropic\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key securely\nuser_secrets = UserSecretsClient()\n\n# Initialize LLM\nmodel = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=user_secrets.get_secret(\"my-openai-api-key\"))\n#model = ChatAnthropic(model=\"claude-3-5-sonnet-latest\", temperature=0, api_key=user_secrets.get_secret(\"my-anthropic-api-key\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:53.91298Z","iopub.execute_input":"2025-01-23T20:17:53.913503Z","iopub.status.idle":"2025-01-23T20:17:54.242375Z","shell.execute_reply.started":"2025-01-23T20:17:53.913419Z","shell.execute_reply":"2025-01-23T20:17:54.241331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Define Tools and Custom Prompt\nThis step defines the tools (e.g., `DuckDuckGoSearchRun`) and a custom prompt for the agent. The prompt instructs the agent to execute tasks step by step.","metadata":{}},{"cell_type":"code","source":"import operator\nfrom typing import Annotated, List, Tuple, Union, Literal\nfrom typing_extensions import TypedDict\nfrom pydantic import BaseModel, Field\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.prebuilt import create_react_agent\n\n# Define Tools\ntools = [DuckDuckGoSearchRun()]\n\n# Define Custom Prompt\ncustom_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant that can execute tasks step by step.\")\n])\n\n# Define Execution Agent\nagent_executor = create_react_agent(model, tools, state_modifier=custom_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:54.243872Z","iopub.execute_input":"2025-01-23T20:17:54.24423Z","iopub.status.idle":"2025-01-23T20:17:54.256973Z","shell.execute_reply.started":"2025-01-23T20:17:54.244195Z","shell.execute_reply":"2025-01-23T20:17:54.255956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Define the State and Planning Logic\nThis step defines the state structure (`PlanExecute`) and the planning logic. The `Plan` class represents the steps to achieve the objective, and the `planner` generates a step-by-step plan.","metadata":{}},{"cell_type":"code","source":"# Define the State\nclass PlanExecute(TypedDict):\n    \"\"\"\n    Represents the state of the execution workflow.\n    \n    Attributes:\n        input (str): The user's input or objective.\n        plan (List[str]): A list of steps to achieve the objective.\n        past_steps (List[Tuple]): A list of tuples representing completed steps and their results.\n        response (str): The final response to the user.\n    \"\"\"\n    input: str\n    plan: List[str]\n    past_steps: Annotated[List[Tuple], operator.add]\n    response: str\n\n# Planning Step\nclass Plan(BaseModel):\n    \"\"\"\n    Represents a plan consisting of steps to achieve an objective.\n    \n    Attributes:\n        steps (List[str]): A list of steps to follow, sorted in the required order.\n    \"\"\"\n    steps: List[str] = Field(description=\"different steps to follow, should be in sorted order\")\n\nplanner_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"For the given objective, come up with a simple step by step plan. \\\nThis plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\nThe result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\"),\n    (\"placeholder\", \"{messages}\")\n])\n\nplanner = planner_prompt | model.with_structured_output(Plan)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:54.258672Z","iopub.execute_input":"2025-01-23T20:17:54.259011Z","iopub.status.idle":"2025-01-23T20:17:54.277977Z","shell.execute_reply.started":"2025-01-23T20:17:54.258983Z","shell.execute_reply":"2025-01-23T20:17:54.276895Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Define Re-Planning Logic\nThis step defines the re-planning logic. The `replanner` updates the plan based on the results of previous steps. If no further steps are needed, it returns the final response.","metadata":{}},{"cell_type":"code","source":"# Re-Plan Step\nclass Response(BaseModel):\n    \"\"\"\n    Represents a response to the user.\n    \n    Attributes:\n        response (str): The final response message.\n    \"\"\"\n    response: str\n\nclass Act(BaseModel):\n    \"\"\"\n    Represents an action to perform, which can be either a response or a new plan.\n    \n    Attributes:\n        action (Union[Response, Plan]): The action to perform. Use `Response` to respond to the user or `Plan` to continue executing steps.\n    \"\"\"\n    action: Union[Response, Plan] = Field(description=\"Action to perform. If you want to respond to user, use Response. If you need to further use tools to get the answer, use Plan.\")\n\nreplanner_prompt = ChatPromptTemplate.from_template(\n    \"\"\"For the given objective, come up with a simple step by step plan. \\\nThis plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\nThe result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n\nYour objective was this:\n{input}\n\nYour original plan was this:\n{plan}\n\nYou have currently done the follow steps:\n{past_steps}\n\nUpdate your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n)\n\nreplanner = replanner_prompt | model.with_structured_output(Act)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:54.279182Z","iopub.execute_input":"2025-01-23T20:17:54.279464Z","iopub.status.idle":"2025-01-23T20:17:54.303087Z","shell.execute_reply.started":"2025-01-23T20:17:54.279423Z","shell.execute_reply":"2025-01-23T20:17:54.302088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Create the Graph and Define Nodes\nThis step creates the workflow graph and defines the nodes (`plan_node`, `agent_node`, `replan_node`). The graph orchestrates the execution of tasks, re-planning, and termination.","metadata":{}},{"cell_type":"code","source":"# Create the Graph\nasync def agent_node(state: PlanExecute) -> PlanExecute:\n    \"\"\"\n    Executes the first step in the plan using the agent.\n\n    Args:\n        state (PlanExecute): The current state of the workflow.\n\n    Returns:\n        PlanExecute: The updated state with the result of the executed step.\n    \"\"\"\n    plan = state[\"plan\"]\n    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n    task = plan[0]\n    task_formatted = f\"For the following plan:\\n{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\n    agent_response = await agent_executor.ainvoke({\"messages\": [(\"user\", task_formatted)]})\n    return {\"past_steps\": [(task, agent_response[\"messages\"][-1].content)]}\n\nasync def plan_node(state: PlanExecute) -> PlanExecute:\n    \"\"\"\n    Generates a plan based on the user's input.\n\n    Args:\n        state (PlanExecute): The current state of the workflow.\n\n    Returns:\n        PlanExecute: The updated state with the generated plan.\n    \"\"\"\n    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n    return {\"plan\": plan.steps}\n\nasync def replan_node(state: PlanExecute) -> PlanExecute:\n    \"\"\"\n    Updates the plan based on the results of previous steps.\n\n    Args:\n        state (PlanExecute): The current state of the workflow.\n\n    Returns:\n        PlanExecute: The updated state with the new plan or final response.\n    \"\"\"\n    output = await replanner.ainvoke(state)\n    if isinstance(output.action, Response):\n        return {\"response\": output.action.response}\n    else:\n        return {\"plan\": output.action.steps}\n\ndef should_end(state: PlanExecute) -> Literal[\"agent_node\", END]:\n    \"\"\"\n    Determines whether the workflow should end or continue.\n\n    Args:\n        state (PlanExecute): The current state of the workflow.\n\n    Returns:\n        Literal[\"agent_node\", END]: Returns `END` if the workflow should terminate, otherwise returns `\"agent_node\"`.\n    \"\"\"\n    if \"response\" in state and state[\"response\"]:\n        return END\n    else:\n        return \"agent_node\"\n\nworkflow = StateGraph(PlanExecute)\nworkflow.add_node(\"plan_node\", plan_node)\nworkflow.add_node(\"agent_node\", agent_node)\nworkflow.add_node(\"replan_node\", replan_node)\n\nworkflow.add_edge(START, \"plan_node\")\nworkflow.add_edge(\"plan_node\", \"agent_node\")\nworkflow.add_edge(\"agent_node\", \"replan_node\")\nworkflow.add_conditional_edges(\"replan_node\", should_end, [\"agent_node\", END])\n\n# Finally, we compile it!\n# This compiles it into a LangChain Runnable,\n# meaning you can use it as you would any other runnable\napp = workflow.compile()\n\nfrom IPython.display import Image, display\ndisplay(Image(app.get_graph(xray=True).draw_mermaid_png()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:54.304081Z","iopub.execute_input":"2025-01-23T20:17:54.304397Z","iopub.status.idle":"2025-01-23T20:17:54.399903Z","shell.execute_reply.started":"2025-01-23T20:17:54.304364Z","shell.execute_reply":"2025-01-23T20:17:54.39893Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Execute the Workflow\nThis step executes the workflow with a sample input. The agent processes the input, generates a plan, executes tasks, and returns the final result.","metadata":{}},{"cell_type":"code","source":"# Example 1: Discovering the Capital City of the 2022 FIFA World Cup Champion\nconfig = {\"recursion_limit\": 30}\ninputs = {\"input\": \"What is the capital city of the country that won the most recent FIFA World Cup?\"}\nasync for event in app.astream(inputs, config=config):\n    for k, v in event.items():\n        if k != \"__end__\":\n            print(v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:17:54.400854Z","iopub.execute_input":"2025-01-23T20:17:54.401197Z","iopub.status.idle":"2025-01-23T20:18:02.494563Z","shell.execute_reply.started":"2025-01-23T20:17:54.40115Z","shell.execute_reply":"2025-01-23T20:18:02.493248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example 2: Population of the Largest City in the Country with the Most Olympic Gold Medals\nconfig = {\"recursion_limit\": 30}\ninputs = {\"input\": \"What is the population of the largest city in the country that has won the most Olympic gold medals?\"}\nasync for event in app.astream(inputs, config=config):\n    for k, v in event.items():\n        if k != \"__end__\":\n            print(v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:28:23.42305Z","iopub.execute_input":"2025-01-23T20:28:23.423358Z","iopub.status.idle":"2025-01-23T20:28:37.164219Z","shell.execute_reply.started":"2025-01-23T20:28:23.423335Z","shell.execute_reply":"2025-01-23T20:28:37.163083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example 3: Currency of the Country with the Highest GDP in 2023\nconfig = {\"recursion_limit\": 30}\ninputs = {\"input\": \"What is the currency of the country with the highest GDP in 2023?\"}\nasync for event in app.astream(inputs, config=config):\n    for k, v in event.items():\n        if k != \"__end__\":\n            print(v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:27:38.566621Z","iopub.execute_input":"2025-01-23T20:27:38.567032Z","iopub.status.idle":"2025-01-23T20:27:45.981277Z","shell.execute_reply.started":"2025-01-23T20:27:38.567002Z","shell.execute_reply":"2025-01-23T20:27:45.98009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example 4: Founder of the Company That Created the Most Popular Smartphone Operating System\nconfig = {\"recursion_limit\": 30}\ninputs = {\"input\": \"Who is the founder of the company that created the most popular smartphone operating system?\"}\nasync for event in app.astream(inputs, config=config):\n    for k, v in event.items():\n        if k != \"__end__\":\n            print(v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T20:27:09.162203Z","iopub.execute_input":"2025-01-23T20:27:09.162588Z","iopub.status.idle":"2025-01-23T20:27:17.439014Z","shell.execute_reply.started":"2025-01-23T20:27:09.16256Z","shell.execute_reply":"2025-01-23T20:27:17.437948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## Conclusion\n\nThe example demonstrates how to build a **dynamic, multi-step task execution workflow** using LangChain and LangGraph. By breaking down complex queries into smaller steps, the agent can efficiently handle tasks that require searching for information, processing results, and providing a final response. The workflow is highly flexible, allowing for dynamic re-planning based on the results of previous steps, and can be adapted to a wide range of use cases.\n\nKey takeaways from this example include:\n- The importance of **state management** in tracking the progress of a multi-step task.\n- The ability to **dynamically re-plan** based on intermediate results, ensuring the workflow adapts to new information.\n- The use of **tools** like `DuckDuckGoSearchRun` to gather information and enhance the agent's capabilities.\n- The **graph-based workflow** design, which provides a clear and modular structure for defining and executing tasks.\n\nThis approach is particularly useful for applications such as **question answering**, **data retrieval**, and **automated decision-making**, where tasks often require multiple steps and dynamic adaptation.","metadata":{}}]}