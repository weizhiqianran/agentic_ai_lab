{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LangChain `SelfQueryRetriever` Quick Reference\n\n## **Introduction**\n\nThe **SelfQueryRetriever** is a powerful tool in the LangChain ecosystem designed to enhance document retrieval by combining **semantic search** with **structured filtering**. Unlike traditional retrieval methods that rely solely on semantic similarity, the SelfQueryRetriever leverages a large language model (LLM) to generate structured queries that can filter documents based on metadata fields such as genre, year, rating, or any other custom attributes. This hybrid approach allows users to perform more precise and context-aware searches, making it an invaluable tool for applications like movie recommendations, product searches, or any domain where metadata plays a crucial role.\n\nThe **SelfQueryRetriever** in LangChain is a specialized retriever designed to enhance retrieval-augmented generation (RAG) systems by combining semantic similarity search with metadata-based filtering. It uses a query-constructing LLM chain to transform natural language queries into structured queries that can be executed on vector databases like Milvus, Pinecone, or Chroma.\n\n### Key Features\n\n1. **Natural Language to Structured Query Conversion**:\n   - The retriever interprets user queries and generates structured queries.\n   - These queries include semantic search criteria and metadata filters, enabling precise document retrieval.\n2. **Metadata Filtering**:\n   - Users can specify conditions (e.g., \"Find documents from 2023\") in their queries.\n   - The retriever applies these conditions to filter results based on metadata fields, such as date, source, or tags.\n3. **Integration with Vector Databases**:\n   - It supports vector stores like Milvus, Pinecone, and Chroma.\n   - The retriever uses the database's capabilities for similarity search and filtering.\n4. **Customizable Query Translators**:\n   - A `structured_query_translator` parameter allows for adapting the retriever to different vector stores by translating internal query formats into database-specific search parameters.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\nThis section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, and Chroma vector store. These libraries include:\n- `langchain-openai`: Provides integration with OpenAI's embedding models.\n- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n- `langchain-chroma`: Enables integration with the Chroma vector database.\n- `chromadb`: The core library for the Chroma vector database.","metadata":{}},{"cell_type":"code","source":"!pip install -qU lark\n!pip install -qU langchain-openai\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langchain-chroma>=0.1.2\n!pip install -qU chromadb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:01:17.808205Z","iopub.execute_input":"2025-01-20T08:01:17.808631Z","iopub.status.idle":"2025-01-20T08:02:38.254652Z","shell.execute_reply.started":"2025-01-20T08:01:17.808591Z","shell.execute_reply":"2025-01-20T08:02:38.253474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initializing OpenAI Embeddings\nThis section demonstrates how to securely fetch an OpenAI API key using Kaggle's `UserSecretsClient` and initialize the OpenAI embedding model. The `OpenAIEmbeddings` class is used to create an embedding model instance, which will be used to convert text into numerical embeddings.\n\nKey steps:\n1. **Fetch API Key**: The OpenAI API key is securely retrieved using Kaggle's `UserSecretsClient`.\n2. **Initialize Embeddings**: The `OpenAIEmbeddings` class is initialized with the `text-embedding-3-small` model and the fetched API key.\n\nThis setup ensures that the embedding model is ready for use in downstream tasks, such as caching embeddings or creating vector stores.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key securely\nuser_secrets = UserSecretsClient()\nmy_api_key = user_secrets.get_secret(\"api-key-openai\")\n\n# Initialize OpenAI embeddings and LLM\nembed = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=my_api_key)\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0, api_key=my_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:02:38.255908Z","iopub.execute_input":"2025-01-20T08:02:38.256217Z","iopub.status.idle":"2025-01-20T08:02:41.276238Z","shell.execute_reply.started":"2025-01-20T08:02:38.256187Z","shell.execute_reply":"2025-01-20T08:02:41.275085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **1. Retrieval Functions**\n\n### **Basic Retrieval with Structured Filtering**\nThis example demonstrates how to use `SelfQueryRetriever` to retrieve documents based on a query with structured filtering (e.g., filtering by metadata like genre and rating).","metadata":{}},{"cell_type":"code","source":"from langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 8.5},\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\"genre\": \"comedy\", \"rating\": 7.0},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Retrieve documents with structured filtering\nresult = retriever.invoke(\"science fiction movie with rating greater than 8\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:04:01.331142Z","iopub.execute_input":"2025-01-20T08:04:01.331542Z","iopub.status.idle":"2025-01-20T08:04:04.061093Z","shell.execute_reply.started":"2025-01-20T08:04:01.331511Z","shell.execute_reply":"2025-01-20T08:04:04.059708Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Retrieval with Custom Metadata**\nThis example extends the basic retrieval by adding custom metadata to the documents and filtering based on it.","metadata":{}},{"cell_type":"code","source":"from langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n    AttributeInfo(\n        name=\"year\",\n        description=\"The year the movie was released\",\n        type=\"integer\",\n    ),\n    AttributeInfo(\n        name=\"director\",\n        description=\"The name of the movie director\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"language\",\n        description=\"The language of the movie\",\n        type=\"string\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with custom metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\n            \"genre\": \"science fiction\",\n            \"rating\": 8.5,\n            \"year\": 2015,\n            \"director\": \"James Cameron\",\n            \"language\": \"English\",\n        },\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\n            \"genre\": \"comedy\",\n            \"rating\": 7.0,\n            \"year\": 2010,\n            \"director\": \"Wes Anderson\",\n            \"language\": \"English\",\n        },\n    ),\n    Document(\n        page_content=\"A thriller about a hacker who uncovers a conspiracy\",\n        metadata={\n            \"genre\": \"thriller\",\n            \"rating\": 9.0,\n            \"year\": 2020,\n            \"director\": \"David Fincher\",\n            \"language\": \"English\",\n        },\n    ),\n    Document(\n        page_content=\"A romantic drama set in Paris\",\n        metadata={\n            \"genre\": \"romance\",\n            \"rating\": 8.0,\n            \"year\": 2018,\n            \"director\": \"Sofia Coppola\",\n            \"language\": \"French\",\n        },\n    ),\n    Document(\n        page_content=\"An animated movie about a robot\",\n        metadata={\n            \"genre\": \"animated\",\n            \"rating\": 9.5,\n            \"year\": 2008,\n            \"director\": \"Andrew Stanton\",\n            \"language\": \"English\",\n        },\n    ),\n]\n\n# Add documents to the vector store\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:06:56.882421Z","iopub.execute_input":"2025-01-20T08:06:56.882898Z","iopub.status.idle":"2025-01-20T08:06:57.606041Z","shell.execute_reply.started":"2025-01-20T08:06:56.882847Z","shell.execute_reply":"2025-01-20T08:06:57.604934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrieve documents with custom metadata filtering\nresult = retriever.invoke(\"comedy movie with rating less than 8\")\nprint(\"Comedy movie with rating less than 8:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:06:57.60753Z","iopub.execute_input":"2025-01-20T08:06:57.607927Z","iopub.status.idle":"2025-01-20T08:06:59.635326Z","shell.execute_reply.started":"2025-01-20T08:06:57.60789Z","shell.execute_reply":"2025-01-20T08:06:59.633932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrieve documents with additional metadata filters\nresult = retriever.invoke(\"science fiction movie directed by James Cameron\")\nprint(\"Science fiction movie directed by James Cameron:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:06:59.63764Z","iopub.execute_input":"2025-01-20T08:06:59.637971Z","iopub.status.idle":"2025-01-20T08:07:01.080524Z","shell.execute_reply.started":"2025-01-20T08:06:59.637943Z","shell.execute_reply":"2025-01-20T08:07:01.079336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = retriever.invoke(\"movie released after 2015\")\nprint(\"Movie released after 2015:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:07:01.081711Z","iopub.execute_input":"2025-01-20T08:07:01.082011Z","iopub.status.idle":"2025-01-20T08:07:02.306187Z","shell.execute_reply.started":"2025-01-20T08:07:01.081987Z","shell.execute_reply":"2025-01-20T08:07:02.304913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = retriever.invoke(\"animated movie with rating greater than 9\")\nprint(\"Animated movie with rating greater than 9:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:07:02.307455Z","iopub.execute_input":"2025-01-20T08:07:02.307916Z","iopub.status.idle":"2025-01-20T08:07:03.885448Z","shell.execute_reply.started":"2025-01-20T08:07:02.307873Z","shell.execute_reply":"2025-01-20T08:07:03.88432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = retriever.invoke(\"French movie\")\nprint(\"French movie:\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:07:03.886525Z","iopub.execute_input":"2025-01-20T08:07:03.887212Z","iopub.status.idle":"2025-01-20T08:07:05.550431Z","shell.execute_reply.started":"2025-01-20T08:07:03.88717Z","shell.execute_reply":"2025-01-20T08:07:05.543861Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"---\n\n## **2. Batch Processing**\n\n### **Batch Retrieval of Multiple Queries**\nThis example demonstrates how to use the `batch` method to process multiple queries at once.","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nfrom langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 8.5},\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\"genre\": \"comedy\", \"rating\": 7.0},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Define multiple queries\nqueries = [\n    \"science fiction movie with rating greater than 8\",\n    \"comedy movie with rating less than 7.5\",\n]\n\n# Perform batch retrieval\nresults = retriever.batch(queries)\nfor result in results:\n    print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:15:44.145968Z","iopub.execute_input":"2025-01-20T08:15:44.1463Z","iopub.status.idle":"2025-01-20T08:15:47.131335Z","shell.execute_reply.started":"2025-01-20T08:15:44.146273Z","shell.execute_reply":"2025-01-20T08:15:47.130141Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Batch Retrieval with Custom Configuration**\nThis example extends the previous one by adding custom configuration (e.g., tags and metadata) to the `batch` method.","metadata":{}},{"cell_type":"code","source":"# Define custom configuration\nconfig = {\"tags\": [\"batch_retrieval\"], \"metadata\": {\"user_id\": 123}}\n\n# Perform batch retrieval with custom configuration\nresults = retriever.batch(queries, config=config)\nfor result in results:\n    print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:16:08.353605Z","iopub.execute_input":"2025-01-20T08:16:08.353994Z","iopub.status.idle":"2025-01-20T08:16:09.925053Z","shell.execute_reply.started":"2025-01-20T08:16:08.353964Z","shell.execute_reply":"2025-01-20T08:16:09.923944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **3. Streaming and Event Handling**\n\n### **Streaming Retrieval Results**\nThis example demonstrates how to use the `stream` method to retrieve documents in a streaming fashion. It includes all necessary imports and defines the `retriever` object.","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nfrom langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 8.5},\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\"genre\": \"comedy\", \"rating\": 7.0},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Stream retrieval results\nfor document in retriever.stream(\"science fiction movie with rating greater than 8\"):\n    print(document)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:16:35.100834Z","iopub.execute_input":"2025-01-20T08:16:35.101196Z","iopub.status.idle":"2025-01-20T08:16:37.384213Z","shell.execute_reply.started":"2025-01-20T08:16:35.101168Z","shell.execute_reply":"2025-01-20T08:16:37.382887Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Handling Retrieval Events**\nThis example extends the previous one by using `astream_events` to handle real-time events during retrieval.","metadata":{}},{"cell_type":"code","source":"# Stream all events during retrieval\nasync for event in retriever.astream_events(\"comedy movie with rating less than 7.5\", version=\"v2\"):\n    print(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:22:49.296581Z","iopub.execute_input":"2025-01-20T08:22:49.296976Z","iopub.status.idle":"2025-01-20T08:22:50.952294Z","shell.execute_reply.started":"2025-01-20T08:22:49.296946Z","shell.execute_reply":"2025-01-20T08:22:50.951015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stream only retriever-related events\nasync for event in retriever.astream_events(\n    \"comedy movie with rating less than 7.5\",\n    version=\"v2\",\n    include_types=[\"retriever\"],\n):\n    print(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:23:01.014924Z","iopub.execute_input":"2025-01-20T08:23:01.015245Z","iopub.status.idle":"2025-01-20T08:23:02.526825Z","shell.execute_reply.started":"2025-01-20T08:23:01.01522Z","shell.execute_reply":"2025-01-20T08:23:02.525245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stream events with specific tags\nasync for event in retriever.astream_events(\n    \"comedy movie with rating less than 7.5\",\n    version=\"v2\",\n    include_tags=[\"my_retriever\"],\n):\n    print(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:23:08.956771Z","iopub.execute_input":"2025-01-20T08:23:08.957146Z","iopub.status.idle":"2025-01-20T08:23:10.52902Z","shell.execute_reply.started":"2025-01-20T08:23:08.957113Z","shell.execute_reply":"2025-01-20T08:23:10.527682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stream events excluding specific types\nasync for event in retriever.astream_events(\n    \"comedy movie with rating less than 7.5\",\n    version=\"v2\",\n    exclude_types=[\"on_retriever_start\"],\n):\n    print(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:23:45.759307Z","iopub.execute_input":"2025-01-20T08:23:45.75965Z","iopub.status.idle":"2025-01-20T08:23:52.079162Z","shell.execute_reply.started":"2025-01-20T08:23:45.759622Z","shell.execute_reply":"2025-01-20T08:23:52.07792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stream events with combined filters\nasync for event in retriever.astream_events(\n    \"comedy movie with rating less than 7.5\",\n    version=\"v2\",\n    include_types=[\"retriever\"],\n    include_tags=[\"my_retriever\"],\n):\n    print(event)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:23:59.647865Z","iopub.execute_input":"2025-01-20T08:23:59.64822Z","iopub.status.idle":"2025-01-20T08:24:02.235556Z","shell.execute_reply.started":"2025-01-20T08:23:59.648194Z","shell.execute_reply":"2025-01-20T08:24:02.234388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a custom event schema\nasync def custom_event_schema(query: str):\n    async for event in retriever.astream_events(query, version=\"v2\"):\n        custom_event = {\n            \"event_name\": event[\"event\"],\n            \"run_id\": event[\"run_id\"],\n            \"data\": event[\"data\"],\n        }\n        print(custom_event)\n\n# Run the custom event schema\nawait custom_event_schema(\"comedy movie with rating less than 7.5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:24:11.383323Z","iopub.execute_input":"2025-01-20T08:24:11.383706Z","iopub.status.idle":"2025-01-20T08:24:13.398327Z","shell.execute_reply.started":"2025-01-20T08:24:11.383672Z","shell.execute_reply":"2025-01-20T08:24:13.396916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **4. Utility Functions and Lifecycle Listeners**\n\n### **Adding Lifecycle Listeners**\nThis example demonstrates how to add lifecycle listeners to the retriever to track its execution. It includes all necessary imports and defines the `retriever` object.","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nfrom langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 8.5},\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\"genre\": \"comedy\", \"rating\": 7.0},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Define lifecycle listeners\ndef on_start(run):\n    print(f\"Retrieval started: {run}\")\n\ndef on_end(run):\n    print(f\"Retrieval ended: {run}\")\n\n# Bind listeners to the retriever\nlistener_retriever = retriever.with_listeners(on_start=on_start, on_end=on_end)\n\n# Invoke the retriever with listeners\nlistener_retriever.invoke(\"science fiction movie with rating greater than 8\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:24:39.302432Z","iopub.execute_input":"2025-01-20T08:24:39.302813Z","iopub.status.idle":"2025-01-20T08:24:43.799484Z","shell.execute_reply.started":"2025-01-20T08:24:39.302765Z","shell.execute_reply":"2025-01-20T08:24:43.798194Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Using Fallback Retrievers**\nThis example extends the previous one by adding fallback retrievers to handle failures gracefully.","metadata":{}},{"cell_type":"code","source":"from langchain_core.runnables import RunnableLambda\n\n# Define a fallback retriever\nfallback_retriever = RunnableLambda(lambda x: [{\"page_content\": \"Fallback document\"}])\n\n# Add fallback to the retriever\nfallback_enabled_retriever = listener_retriever.with_fallbacks([fallback_retriever])\n\n# Invoke the retriever with fallback\nresult = fallback_enabled_retriever.invoke(\"invalid query\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:24:50.733995Z","iopub.execute_input":"2025-01-20T08:24:50.734355Z","iopub.status.idle":"2025-01-20T08:24:51.95037Z","shell.execute_reply.started":"2025-01-20T08:24:50.734325Z","shell.execute_reply":"2025-01-20T08:24:51.949273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **5. Configuration and Customization**\n\n### **Customizing Search Parameters**\nThis example demonstrates how to customize search parameters (e.g., search type and keyword arguments). It includes all necessary imports and defines the `retriever` object.","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nfrom langchain_chroma import Chroma\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_core.documents import Document\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\",\n        description=\"A 1-10 rating for the movie\",\n        type=\"float\",\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A space adventure with aliens\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 8.5},\n    ),\n    Document(\n        page_content=\"A comedy about life in a small town\",\n        metadata={\"genre\": \"comedy\", \"rating\": 7.0},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Create SelfQueryRetriever\nretriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Customize search parameters\ncustom_retriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n    search_type=\"mmr\",  # Maximal Marginal Relevance\n    search_kwargs={\"k\": 5},  # Retrieve top 5 documents\n)\n\n# Retrieve documents with custom search parameters\nresult = custom_retriever.invoke(\"science fiction movie with rating greater than 8\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:25:06.294404Z","iopub.execute_input":"2025-01-20T08:25:06.294905Z","iopub.status.idle":"2025-01-20T08:25:11.060141Z","shell.execute_reply.started":"2025-01-20T08:25:06.294852Z","shell.execute_reply":"2025-01-20T08:25:11.058884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Configurable Alternatives for Retrieval**\nThis example extends the previous one by using `configurable_alternatives` to switch between different retrievers at runtime.","metadata":{}},{"cell_type":"code","source":"from langchain_core.runnables import ConfigurableField\n\n# Define alternative retrievers\nalternative_retriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n    search_type=\"similarity\",  # Alternative search type\n)\n\n# Configure alternatives\nconfigurable_retriever = custom_retriever.configurable_alternatives(\n    ConfigurableField(id=\"retriever\"),\n    default_key=\"default\",\n    alternative=alternative_retriever,\n)\n\n# Use the default retriever\nresult = configurable_retriever.invoke(\"science fiction movie with rating greater than 8\")\nprint(result)\n\n# Switch to the alternative retriever\nresult = configurable_retriever.with_config(configurable={\"retriever\": \"alternative\"}).invoke(\"comedy movie with rating less than 7.5\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:25:20.19537Z","iopub.execute_input":"2025-01-20T08:25:20.195747Z","iopub.status.idle":"2025-01-20T08:25:23.132972Z","shell.execute_reply.started":"2025-01-20T08:25:20.195709Z","shell.execute_reply":"2025-01-20T08:25:23.131886Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Best Practices**\n\n### **Customizing SelfQueryRetriever to Include Similarity Scores**\nThis example demonstrates how to subclass `SelfQueryRetriever` to include similarity scores in the document metadata. This is useful for understanding how closely each document matches the query.","metadata":{}},{"cell_type":"code","source":"from langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain_core.documents import Document\nfrom typing import Any, Dict, List\n\n# Define metadata fields for filtering\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"genre\",\n        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"year\",\n        description=\"The year the movie was released\",\n        type=\"integer\",\n    ),\n    AttributeInfo(\n        name=\"director\",\n        description=\"The name of the movie director\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"rating\", \n        description=\"A 1-10 rating for the movie\", \n        type=\"float\"\n    ),\n]\ndocument_content_description = \"Brief summary of a movie\"\n\n# Initialize vector store and embeddings\nembed = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=my_api_key)\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0, api_key=my_api_key)\nvectorstore = Chroma(embedding_function=embed)\n\n# Add documents with metadata to the vector store\ndocuments = [\n    Document(\n        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n        metadata={\"genre\": \"science fiction\", \"rating\": 7.7, \"year\": 1993, \"director\": \"Steven Spielberg\"},\n    ),\n    Document(\n        page_content=\"A heartwarming story about a boy and his dog\",\n        metadata={\"genre\": \"drama\", \"rating\": 8.5, \"year\": 2009, \"director\": \"Lasse Hallström\"},\n    ),\n]\nvectorstore.add_documents(documents)\n\n# Subclass SelfQueryRetriever to include similarity scores\nclass CustomSelfQueryRetriever(SelfQueryRetriever):\n    def _get_docs_with_query(\n        self, query: str, search_kwargs: Dict[str, Any]\n    ) -> List[Document]:\n        \"\"\"Get docs, adding score information.\"\"\"\n        try:\n            # Perform similarity search with scores\n            results = self.vectorstore.similarity_search_with_score(query, **search_kwargs)\n            if not results:\n                print(\"No documents matched the query.\")\n                return []\n            \n            docs, scores = zip(*results)\n            for doc, score in zip(docs, scores):\n                doc.metadata[\"score\"] = score\n            return list(docs)\n        except Exception as e:\n            print(f\"An error occurred during retrieval: {e}\")\n            return []\n\n# Create the custom retriever\nretriever = CustomSelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n)\n\n# Retrieve documents with similarity scores\nresult = retriever.invoke(\"dinosaur movie with rating less than 8\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:38:35.491678Z","iopub.execute_input":"2025-01-20T08:38:35.49213Z","iopub.status.idle":"2025-01-20T08:38:37.892259Z","shell.execute_reply.started":"2025-01-20T08:38:35.492097Z","shell.execute_reply":"2025-01-20T08:38:37.891103Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Filtering Documents by Multiple Metadata Fields**\nThis example demonstrates how to use `SelfQueryRetriever` to filter documents based on multiple metadata fields (e.g., genre, year, and rating).","metadata":{}},{"cell_type":"code","source":"# Retrieve documents with multiple metadata filters\nresult = retriever.invoke(\"science fiction movie released after 1990 with rating greater than 7\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:38:41.402323Z","iopub.execute_input":"2025-01-20T08:38:41.402734Z","iopub.status.idle":"2025-01-20T08:38:43.118131Z","shell.execute_reply.started":"2025-01-20T08:38:41.4027Z","shell.execute_reply":"2025-01-20T08:38:43.116962Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Using SelfQueryRetriever with Custom Search Parameters**\nThis example demonstrates how to customize the search parameters (e.g., search type and keyword arguments) for `SelfQueryRetriever`.","metadata":{}},{"cell_type":"code","source":"# Customize search parameters\ncustom_retriever = SelfQueryRetriever.from_llm(\n    model,\n    vectorstore,\n    document_content_description,\n    metadata_field_info,\n    search_type=\"mmr\",       # Maximal Marginal Relevance\n    search_kwargs={\"k\": 5},  # Retrieve top 5 documents\n)\n\n# Retrieve documents with custom search parameters\nresult = custom_retriever.invoke(\"drama movie with rating greater than 8\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:38:46.233747Z","iopub.execute_input":"2025-01-20T08:38:46.234277Z","iopub.status.idle":"2025-01-20T08:38:48.568658Z","shell.execute_reply.started":"2025-01-20T08:38:46.234234Z","shell.execute_reply":"2025-01-20T08:38:48.567654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Handling Edge Cases with Fallback Retrievers**\nThis example demonstrates how to add fallback retrievers to handle cases where no documents match the query.","metadata":{}},{"cell_type":"code","source":"from langchain_core.runnables import RunnableLambda\n\n# Define a fallback retriever\nfallback_retriever = RunnableLambda(lambda x: [{\"page_content\": \"No matching documents found.\"}])\n\n# Add fallback to the retriever\nfallback_enabled_retriever = retriever.with_fallbacks([fallback_retriever])\n\n# Invoke the retriever with fallback\nresult = fallback_enabled_retriever.invoke(\"horror movie with rating greater than 9\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T08:38:51.128992Z","iopub.execute_input":"2025-01-20T08:38:51.129366Z","iopub.status.idle":"2025-01-20T08:38:52.531913Z","shell.execute_reply.started":"2025-01-20T08:38:51.129327Z","shell.execute_reply":"2025-01-20T08:38:52.53086Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Conclusion**\n\nThe **SelfQueryRetriever** is a game-changer for applications that require both semantic understanding and structured filtering. By combining the strengths of large language models and metadata-aware retrieval, it provides a flexible and powerful solution for a wide range of use cases. Whether you're building a movie recommendation system, an e-commerce search engine, or any application that relies on metadata, the SelfQueryRetriever can significantly enhance the user experience by delivering more accurate and relevant results.\n\nIts ability to **automatically generate structured queries** from natural language inputs makes it accessible to users without technical expertise, while its support for **custom metadata fields** ensures that it can adapt to diverse application requirements. Additionally, features like **similarity score propagation** and **fallback mechanisms** further enhance its robustness and usability.\n\nIn conclusion, the **SelfQueryRetriever** is not just a tool for retrieving documents—it's a comprehensive solution for building intelligent, metadata-aware search systems. By leveraging its capabilities, developers can create applications that are both user-friendly and highly effective, ensuring that users can find the information they need quickly and accurately.","metadata":{}}]}