{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LangChain EnsembleRetriever Quick Reference\n\n## Introduction\n\nThe **EnsembleRetriever** is a powerful retrieval mechanism within the LangChain framework designed to enhance information retrieval by combining the results of multiple retrievers. By leveraging the strengths of different retrieval algorithms, the EnsembleRetriever achieves superior performance compared to using a single retriever. This approach, often referred to as \"hybrid search,\" integrates sparse retrievers (e.g., BM25) and dense retrievers (e.g., Chroma or FAISS) to provide a more comprehensive and accurate retrieval system.\n\n### Key Features\n- **Combination of Multiple Retrievers**: The EnsembleRetriever integrates various retrieval methods, such as sparse and dense retrievers, to handle diverse query types and document structures.\n- **Reranking Mechanism**: It uses the **Reciprocal Rank Fusion (RRF)** algorithm to rerank results from individual retrievers, ensuring the most relevant documents are prioritized.\n- **Improved Performance**: By combining keyword-based and semantic-based retrieval, the EnsembleRetriever delivers better accuracy and relevance, especially in complex search scenarios.\n- **Customizable Weights**: Users can assign weights to individual retrievers to prioritize specific retrieval methods based on their strengths.\n- **Runtime Configuration**: The retriever supports dynamic configuration, allowing users to adjust parameters (e.g., the number of documents to retrieve) at runtime.\n\n### Use Cases\n1. **Hybrid Search**: Combining sparse and dense retrievers to handle both keyword-based and semantic-based queries effectively.\n2. **Domain-Specific Retrieval**: Integrating custom retrievers for specialized domains (e.g., legal, medical, or scientific documents).\n3. **Metadata Filtering**: Refining search results by filtering documents based on metadata (e.g., source, date, or category).\n4. **Dynamic Query Handling**: Adjusting retrieval strategies at runtime to adapt to different query types or user preferences.\n5. **Enhanced Search Relevance**: Improving search relevance in applications like chatbots, recommendation systems, and knowledge bases.\n\n### Comparison Table: Sparse vs. Dense vs. Hybrid Retrieval\n\n| Feature                | Sparse Retrieval (e.g., BM25)       | Dense Retrieval (e.g., Chroma)      | Hybrid Retrieval (EnsembleRetriever) |\n|------------------------|-------------------------------------|-------------------------------------|--------------------------------------|\n| **Strengths**          | Keyword-based matching              | Semantic similarity matching        | Combines both keyword and semantic   |\n| **Weaknesses**         | Struggles with semantic queries     | Struggles with exact keyword match  | Requires more computational resources|\n| **Use Cases**          | Keyword-heavy queries               | Semantic-heavy queries              | Complex queries requiring both       |\n| **Performance**        | Fast for exact keyword searches     | Slower but more accurate for semantics | Balanced performance for hybrid tasks|\n| **Customization**      | Limited to keyword-based tuning     | Limited to embedding-based tuning   | Highly customizable with weights     |","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\nThis section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, and Chroma vector store. These libraries include:\n- `langchain-openai`: Provides integration with OpenAI's embedding models.\n- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n- `langchain-chroma`: Enables integration with the Chroma vector database.\n- `chromadb`: The core library for the Chroma vector database.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langchain-chroma>=0.1.2\n!pip install -qU chromadb\n!pip install -qU rank_bm25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:24:56.807874Z","iopub.execute_input":"2025-01-20T09:24:56.80814Z","iopub.status.idle":"2025-01-20T09:26:14.593137Z","shell.execute_reply.started":"2025-01-20T09:24:56.808117Z","shell.execute_reply":"2025-01-20T09:26:14.591693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initializing OpenAI Embeddings\nThis section demonstrates how to securely fetch an OpenAI API key using Kaggle's `UserSecretsClient` and initialize the OpenAI embedding model. The `OpenAIEmbeddings` class is used to create an embedding model instance, which will be used to convert text into numerical embeddings.\n\nKey steps:\n1. **Fetch API Key**: The OpenAI API key is securely retrieved using Kaggle's `UserSecretsClient`.\n2. **Initialize Embeddings**: The `OpenAIEmbeddings` class is initialized with the `text-embedding-3-small` model and the fetched API key.\n\nThis setup ensures that the embedding model is ready for use in downstream tasks, such as caching embeddings or creating vector stores.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key securely\nuser_secrets = UserSecretsClient()\nmy_api_key = user_secrets.get_secret(\"api-key-openai\")\n\n# Initialize OpenAI embeddings\nembed = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=my_api_key)\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0, api_key=my_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:26:14.594558Z","iopub.execute_input":"2025-01-20T09:26:14.59501Z","iopub.status.idle":"2025-01-20T09:26:17.539233Z","shell.execute_reply.started":"2025-01-20T09:26:14.594978Z","shell.execute_reply":"2025-01-20T09:26:17.538028Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 1. Document Retrieval and Management\n\n### Example 1: Basic Ensemble Retrieval\nThis example demonstrates how to initialize an `EnsembleRetriever` with a BM25 retriever and a Chroma vector store retriever, and then retrieve documents for a query.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:26:17.540463Z","iopub.execute_input":"2025-01-20T09:26:17.540976Z","iopub.status.idle":"2025-01-20T09:26:20.886408Z","shell.execute_reply.started":"2025-01-20T09:26:17.540937Z","shell.execute_reply":"2025-01-20T09:26:20.88538Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Customizing Retrieval Parameters\nThis example shows how to customize the retrieval parameters, such as the number of documents to retrieve (`k`) and the weights assigned to each retriever.","metadata":{}},{"cell_type":"code","source":"# Update BM25 retriever to return top 3 documents\nbm25_retriever.k = 3\n\n# Update Chroma retriever to return top 3 documents\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n\n# Reinitialize EnsembleRetriever with updated weights\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.7, 0.3]\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"oranges\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:26:56.314668Z","iopub.execute_input":"2025-01-20T09:26:56.315078Z","iopub.status.idle":"2025-01-20T09:26:56.69384Z","shell.execute_reply.started":"2025-01-20T09:26:56.315045Z","shell.execute_reply":"2025-01-20T09:26:56.692911Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 2. Batch Processing\n\n### Example 1: Batch Retrieval\nThis example demonstrates how to use the `batch` method to retrieve documents for multiple queries in parallel.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Define multiple queries\nqueries = [\"apples\", \"oranges\", \"fruits\"]\n\n# Retrieve documents for all queries in batch\nbatch_docs = ensemble_retriever.batch(queries)\nfor query, docs in zip(queries, batch_docs):\n    print(f\"Query: {query}\")\n    print(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:27:11.644186Z","iopub.execute_input":"2025-01-20T09:27:11.644619Z","iopub.status.idle":"2025-01-20T09:27:13.579796Z","shell.execute_reply.started":"2025-01-20T09:27:11.64459Z","shell.execute_reply":"2025-01-20T09:27:13.578569Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Batch Retrieval with Custom Configuration\nThis example shows how to apply custom configurations (e.g., adjusting `k` for the Chroma retriever) during batch retrieval.","metadata":{}},{"cell_type":"code","source":"# Define a custom configuration for the Chroma retriever\nconfig = {\"configurable\": {\"search_kwargs\": {\"k\": 1}}}\n\n# Retrieve documents for all queries in batch with custom configuration\nbatch_docs = ensemble_retriever.batch(queries, config=config)\nfor query, docs in zip(queries, batch_docs):\n    print(f\"Query: {query}\")\n    print(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:27:25.305714Z","iopub.execute_input":"2025-01-20T09:27:25.306137Z","iopub.status.idle":"2025-01-20T09:27:25.77655Z","shell.execute_reply.started":"2025-01-20T09:27:25.306107Z","shell.execute_reply":"2025-01-20T09:27:25.775495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 3. Streaming\n\n### Example 1: Streaming Retrieval Results\nThis example demonstrates how to stream retrieval results for a query.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Stream documents for a query\nfor doc in ensemble_retriever.stream(\"apples\"):\n    print(doc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:27:38.063902Z","iopub.execute_input":"2025-01-20T09:27:38.064281Z","iopub.status.idle":"2025-01-20T09:27:38.696767Z","shell.execute_reply.started":"2025-01-20T09:27:38.064254Z","shell.execute_reply":"2025-01-20T09:27:38.69586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Customizing Streaming Behavior\nThis example shows how to customize the streaming behavior by adjusting the number of documents streamed.","metadata":{}},{"cell_type":"code","source":"# Update Chroma retriever to return only 1 document during streaming\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n\n# Reinitialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Stream documents for a query\nfor doc in ensemble_retriever.stream(\"oranges\"):\n    print(doc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:27:47.576265Z","iopub.execute_input":"2025-01-20T09:27:47.57658Z","iopub.status.idle":"2025-01-20T09:27:48.104092Z","shell.execute_reply.started":"2025-01-20T09:27:47.576557Z","shell.execute_reply":"2025-01-20T09:27:48.103118Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 4. Error Handling and Retries\n\n### Example 1: Adding Fallback Retrievers\nThis example demonstrates how to add fallback retrievers to handle failures.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\nfrom langchain_core.runnables import RunnableLambda\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Define a fallback retriever\nfallback_retriever = RunnableLambda(lambda x: [{\"page_content\": \"Fallback document\", \"metadata\": {\"source\": \"fallback\"}}])\n\n# Add fallback to the ensemble retriever\nensemble_retriever_with_fallback = ensemble_retriever.with_fallbacks([fallback_retriever])\n\n# Retrieve documents (fallback will be used if primary retrievers fail)\ndocs = ensemble_retriever_with_fallback.invoke(\"unknown query\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:27:59.361326Z","iopub.execute_input":"2025-01-20T09:27:59.361654Z","iopub.status.idle":"2025-01-20T09:27:59.901495Z","shell.execute_reply.started":"2025-01-20T09:27:59.361631Z","shell.execute_reply":"2025-01-20T09:27:59.900415Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Retrying on Failure\nThis example shows how to configure the retriever to retry on specific exceptions.","metadata":{}},{"cell_type":"code","source":"# Configure retries for the ensemble retriever\nensemble_retriever_with_retry = ensemble_retriever.with_retry(\n    retry_if_exception_type=(ValueError,), stop_after_attempt=3\n)\n\n# Retrieve documents (retries will be attempted on failure)\ndocs = ensemble_retriever_with_retry.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:28:08.041839Z","iopub.execute_input":"2025-01-20T09:28:08.042216Z","iopub.status.idle":"2025-01-20T09:28:08.286117Z","shell.execute_reply.started":"2025-01-20T09:28:08.042178Z","shell.execute_reply":"2025-01-20T09:28:08.284958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 5. Lifecycle Listeners\n\n### Example 1: Adding Lifecycle Listeners\nThis example demonstrates how to add lifecycle listeners to the retriever.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Define lifecycle listeners\ndef on_start(run_obj):\n    print(f\"Retrieval started with input: {run_obj.inputs}\")\n\ndef on_end(run_obj):\n    print(f\"Retrieval ended with output: {run_obj.outputs}\")\n\n# Add lifecycle listeners to the ensemble retriever\nensemble_retriever_with_listeners = ensemble_retriever.with_listeners(\n    on_start=on_start, on_end=on_end\n)\n\n# Retrieve documents (listeners will be triggered)\ndocs = ensemble_retriever_with_listeners.invoke(\"oranges\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:28:18.791934Z","iopub.execute_input":"2025-01-20T09:28:18.792302Z","iopub.status.idle":"2025-01-20T09:28:19.295423Z","shell.execute_reply.started":"2025-01-20T09:28:18.792275Z","shell.execute_reply":"2025-01-20T09:28:19.294235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Customizing Listener Behavior\nThis example shows how to customize listener behavior by adding metadata to the run.","metadata":{}},{"cell_type":"code","source":"def on_start_with_metadata(run_obj):\n    print(f\"Retrieval started with input: {run_obj.inputs} and metadata: {run_obj.metadata}\")\n\n# Add lifecycle listeners with metadata\nensemble_retriever_with_listeners = ensemble_retriever.with_listeners(\n    on_start=on_start_with_metadata, on_end=on_end\n)\n\n# Retrieve documents (listeners will be triggered with metadata)\ndocs = ensemble_retriever_with_listeners.invoke(\"apples\", config={\"metadata\": {\"user\": \"test\"}})\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:28:31.461957Z","iopub.execute_input":"2025-01-20T09:28:31.46236Z","iopub.status.idle":"2025-01-20T09:28:31.787907Z","shell.execute_reply.started":"2025-01-20T09:28:31.462331Z","shell.execute_reply":"2025-01-20T09:28:31.78693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 6. Configuration and Binding\n\n### Example 1: Binding Configuration at Runtime\nThis example demonstrates how to bind configuration (e.g., adjusting `k` for the Chroma retriever) at runtime.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\nfrom langchain_core.runnables import ConfigurableField\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma vector store retriever\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(\n    search_kwargs={\"k\": 2}\n).configurable_fields(\n    search_kwargs=ConfigurableField(\n        id=\"search_kwargs_chroma\",\n        name=\"Search Kwargs\",\n        description=\"The search kwargs to use\",\n    )\n)\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Bind configuration at runtime\nconfig = {\"configurable\": {\"search_kwargs_chroma\": {\"k\": 1}}}\ndocs = ensemble_retriever.invoke(\"oranges\", config=config)\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:28:45.334875Z","iopub.execute_input":"2025-01-20T09:28:45.335268Z","iopub.status.idle":"2025-01-20T09:28:45.995915Z","shell.execute_reply.started":"2025-01-20T09:28:45.33524Z","shell.execute_reply":"2025-01-20T09:28:45.994885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Binding Arguments to the Retriever\nThis example shows how to bind additional arguments to the retriever.","metadata":{}},{"cell_type":"code","source":"# Bind additional arguments to the retriever\nensemble_retriever_with_args = ensemble_retriever.bind(k=1)\n\n# Retrieve documents with bound arguments\ndocs = ensemble_retriever_with_args.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:28:55.062135Z","iopub.execute_input":"2025-01-20T09:28:55.062485Z","iopub.status.idle":"2025-01-20T09:28:55.194636Z","shell.execute_reply.started":"2025-01-20T09:28:55.062458Z","shell.execute_reply":"2025-01-20T09:28:55.193465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## Best Practices\n\nThe **Best Practices** examples demonstrate how to effectively use the `EnsembleRetriever` in LangChain to combine multiple retrieval techniques for improved document retrieval. These examples highlight key features and configurations, such as:\n\n1. **Hybrid Search**: Combining sparse (keyword-based) and dense (semantic-based) retrievers to leverage their complementary strengths.\n2. **Runtime Configuration**: Dynamically adjusting retriever parameters (e.g., the number of documents to retrieve) at runtime.\n3. **Custom Weighting**: Assigning custom weights to prioritize specific retrievers in the ensemble.\n4. **Custom Retrievers**: Integrating custom retrieval logic into the ensemble for domain-specific use cases.\n5. **Metadata Filtering**: Refining search results by filtering documents based on metadata.\n\nEach example builds on a common setup (e.g., BM25 and Chroma retrievers) to ensure consistency and reduce redundancy, making them easy to follow and implement in a Kaggle notebook or similar environment. These examples are designed to help users understand and apply advanced retrieval techniques in real-world scenarios.\n\n### Example 1: Combining Sparse and Dense Retrievers for Hybrid Search\nThis example demonstrates how to combine a sparse retriever (`BM25Retriever`) and a dense retriever (`Chroma Retriever`) using the `EnsembleRetriever`. This hybrid approach leverages the strengths of both keyword-based and semantic search.","metadata":{}},{"cell_type":"code","source":"from langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever\nfrom langchain_chroma import Chroma\nfrom langchain_openai import OpenAIEmbeddings\n\n# Sample documents\ndoc_list_1 = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\ndoc_list_2 = [\n    \"You like apples\",\n    \"You like oranges\",\n]\n\n# Initialize BM25 retriever (sparse)\nbm25_retriever = BM25Retriever.from_texts(\n    doc_list_1, metadatas=[{\"source\": 1}] * len(doc_list_1)\n)\nbm25_retriever.k = 2\n\n# Initialize Chroma retriever (dense)\nchroma_vectorstore = Chroma.from_texts(\n    doc_list_2, embed, metadatas=[{\"source\": 2}] * len(doc_list_2)\n)\nchroma_retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# Initialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:36:50.995335Z","iopub.execute_input":"2025-01-20T09:36:50.995711Z","iopub.status.idle":"2025-01-20T09:36:54.746222Z","shell.execute_reply.started":"2025-01-20T09:36:50.995682Z","shell.execute_reply":"2025-01-20T09:36:54.744943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Configuring Retrievers at Runtime\nThis example shows how to configure the parameters of individual retrievers (e.g., adjusting the number of documents to retrieve) at runtime using `ConfigurableField`.","metadata":{}},{"cell_type":"code","source":"from langchain_core.runnables import ConfigurableField\n\n# Make the Chroma retriever configurable\nchroma_retriever = chroma_vectorstore.as_retriever(\n    search_kwargs={\"k\": 2}\n).configurable_fields(\n    search_kwargs=ConfigurableField(\n        id=\"search_kwargs_chroma\",\n        name=\"Search Kwargs\",\n        description=\"The search kwargs to use\",\n    )\n)\n\n# Reinitialize EnsembleRetriever with the configurable Chroma retriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Configure Chroma retriever at runtime\nconfig = {\"configurable\": {\"search_kwargs_chroma\": {\"k\": 1}}}\ndocs = ensemble_retriever.invoke(\"apples\", config=config)\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:37:01.012692Z","iopub.execute_input":"2025-01-20T09:37:01.013167Z","iopub.status.idle":"2025-01-20T09:37:01.318114Z","shell.execute_reply.started":"2025-01-20T09:37:01.01313Z","shell.execute_reply":"2025-01-20T09:37:01.316928Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 3: Adjusting Retriever Weights for Custom Prioritization\nThis example demonstrates how to adjust the weights assigned to each retriever in the ensemble to prioritize one retriever over another.","metadata":{}},{"cell_type":"code","source":"# Reinitialize EnsembleRetriever with custom weights\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.7, 0.3]\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"oranges\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:37:07.304407Z","iopub.execute_input":"2025-01-20T09:37:07.304781Z","iopub.status.idle":"2025-01-20T09:37:08.541555Z","shell.execute_reply.started":"2025-01-20T09:37:07.304747Z","shell.execute_reply":"2025-01-20T09:37:08.540271Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 4: Combining Multiple Retrievers for Enhanced Results\nThis example demonstrates how to combine more than two retrievers (e.g., BM25, Chroma, and a custom retriever) to further enhance retrieval performance.","metadata":{}},{"cell_type":"code","source":"from langchain_core.documents import Document\nfrom langchain_core.runnables import RunnableLambda\n\n# Define a custom retriever that returns Document objects\ndef custom_retriever(query: str) -> list:\n    return [\n        Document(\n            page_content=\"Custom document\",\n            metadata={\"source\": \"custom\"}\n        )\n    ]\n\n# Wrap the custom retriever in a RunnableLambda\ncustom_retriever_runnable = RunnableLambda(custom_retriever)\n\n# Initialize EnsembleRetriever with multiple retrievers\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever, custom_retriever_runnable],\n    weights=[0.4, 0.4, 0.2],\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:37:14.256502Z","iopub.execute_input":"2025-01-20T09:37:14.256957Z","iopub.status.idle":"2025-01-20T09:37:14.717284Z","shell.execute_reply.started":"2025-01-20T09:37:14.256918Z","shell.execute_reply":"2025-01-20T09:37:14.716349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 5: Using EnsembleRetriever with Metadata Filtering\nThis example demonstrates how to use metadata filtering with the `EnsembleRetriever` to refine search results.","metadata":{}},{"cell_type":"code","source":"# Reinitialize Chroma retriever with metadata filtering\nchroma_retriever = chroma_vectorstore.as_retriever(\n    search_kwargs={\"k\": 2, \"filter\": {\"source\": 2}}\n)\n\n# Reinitialize EnsembleRetriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n)\n\n# Retrieve documents\ndocs = ensemble_retriever.invoke(\"apples\")\nprint(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T09:37:22.60257Z","iopub.execute_input":"2025-01-20T09:37:22.602943Z","iopub.status.idle":"2025-01-20T09:37:23.356598Z","shell.execute_reply.started":"2025-01-20T09:37:22.602914Z","shell.execute_reply":"2025-01-20T09:37:23.355234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nThe **EnsembleRetriever** is a versatile and powerful tool for enhancing information retrieval systems. By combining the strengths of sparse and dense retrievers, it addresses the limitations of individual retrieval methods and provides a more robust solution for complex search tasks. Its ability to rerank results using the Reciprocal Rank Fusion algorithm ensures that the most relevant documents are prioritized, while its support for runtime configuration and custom weights makes it highly adaptable to various use cases.\n\nWhether you're building a chatbot, a recommendation system, or a knowledge base, the EnsembleRetriever offers a flexible and effective way to improve search relevance and accuracy. Its hybrid approach makes it particularly valuable in scenarios where both keyword-based and semantic-based retrieval are required.","metadata":{}}]}