{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hierarchical Agent Teams\n\n## Introduction\n\nAs tasks grow in complexity or scale, managing them with a single supervisor node may become inefficient. A single supervisor can route tasks between workers, but what happens when individual tasks require intricate subtasks or when the number of workers becomes overwhelming?\n\nIn such scenarios, a hierarchical structure becomes a powerful solution. By breaking down tasks into sub-tasks and organizing workers into teams with their own supervisors, we can create a robust and scalable system. Each team handles a specific domain of tasks, and mid-level supervisors coordinate efforts before reporting to a top-level supervisor.\n\nThis approach enables efficient task distribution, better resource management, and improved scalability for complex workflows.\n\n**In this notebook, we will**:\n\n- Define tools for agents to access web data and manage files\n- Implement utilities to streamline the creation of task workflows\n- Develop teams specialized in web research and document writing\n- Compose these components into a hierarchical system of supervisors and workers","metadata":{}},{"cell_type":"markdown","source":"## Installation of Required Packages\n\nFirst, we need to install the necessary packages required for our hierarchical agent system. These packages include various components of LangChain, LangGraph, ChromaDB, DuckDuckGo search, and Wikipedia integration.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU chromadb\n!pip install -qU duckduckgo_search\n!pip install -qU wikipedia","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T05:58:30.537861Z","iopub.execute_input":"2025-01-15T05:58:30.538193Z","iopub.status.idle":"2025-01-15T05:59:58.964483Z","shell.execute_reply.started":"2025-01-15T05:58:30.538157Z","shell.execute_reply":"2025-01-15T05:59:58.963078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Modules and Setting Up the Environment\n\nIn this section, we import all the necessary modules and set up the environment variables. We also define the tools that our agents will use, such as web scraping, document writing, and Python REPL execution.","metadata":{}},{"cell_type":"code","source":"import os\n\n# Set a custom user agent for HTTP requests\nos.environ[\"USER_AGENT\"] = \"MyApp/1.0 (https://myapp.com; contact@myapp.com)\"\n\nfrom typing import Annotated, List, Dict, Optional, Literal\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_core.tools import tool\nfrom langchain_experimental.utilities import PythonREPL\nfrom langchain_core.language_models.chat_models import BaseChatModel\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.types import Command\nfrom langchain_core.messages import BaseMessage, HumanMessage, trim_messages\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\nfrom typing_extensions import TypedDict\nfrom IPython.display import Image, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:07:26.625916Z","iopub.execute_input":"2025-01-15T06:07:26.626492Z","iopub.status.idle":"2025-01-15T06:07:29.188072Z","shell.execute_reply.started":"2025-01-15T06:07:26.626437Z","shell.execute_reply":"2025-01-15T06:07:29.187193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating Tools for the Research Team\n\nHere, we define the tools that the Research Team will use. This includes a search tool using DuckDuckGo and a web scraping tool to extract information from provided URLs.","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------------------------------------------------\n# Create Tools\n# --------------------------------------------------------------------------------------------------------\n\n# Research Team Tools\n# Search tool using DuckDuckGo\nsearch_tool = DuckDuckGoSearchRun()\n\n@tool\ndef scrape_webpages(urls: List[str]) -> str:\n    \"\"\"\n    Scrapes the provided web pages for detailed information using WebBaseLoader.\n    Args:\n        urls (List[str]): A list of URLs to scrape.\n    Returns:\n        str: A string containing the scraped content in a structured format.\n    \"\"\"\n    loader = WebBaseLoader(urls)\n    docs = loader.load()\n    return \"\\n\\n\".join(\n        [\n            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n            for doc in docs\n        ]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:07:29.189548Z","iopub.execute_input":"2025-01-15T06:07:29.190153Z","iopub.status.idle":"2025-01-15T06:07:29.282878Z","shell.execute_reply.started":"2025-01-15T06:07:29.190114Z","shell.execute_reply":"2025-01-15T06:07:29.281955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating Tools for the Document Writing Team\n\nThe Document Writing Team requires tools to create outlines, read, write, and edit documents. We set up these tools along with a temporary directory for file operations. A temporary directory is created for file operations, and the following tools are implemented:\n\n1. **`create_outline`**:  \n   Creates an outline from a list of points and saves it to a specified file.  \n   Example: `create_outline([\"Introduction\", \"Methodology\"], \"outline.txt\")`.\n\n2. **`read_document`**:  \n   Reads content from a file, optionally specifying a start and end line for partial reading.  \n   Example: `read_document(\"outline.txt\", start=0, end=2)`.\n\n3. **`write_document`**:  \n   Writes provided content to a specified file.  \n   Example: `write_document(\"This is the content.\", \"document.txt\")`.\n\n4. **`edit_document`**:  \n   Edits a document by inserting text at specific line numbers (1-indexed).  \n   Example: `edit_document(\"document.txt\", {2: \"This is an inserted line.\"})`.\n\nEach tool operates within the temporary directory and returns a confirmation message with the file path or the content read. These tools enable the Document Writing Team to perform file-based operations efficiently.","metadata":{}},{"cell_type":"code","source":"# Document Writing Team Tools\n# Create a temporary directory for file operations\n_TEMP_DIRECTORY = TemporaryDirectory()\nWORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n\n@tool\ndef create_outline(\n    points: Annotated[List[str], \"List of main points or sections.\"],\n    file_name: Annotated[str, \"File path to save the outline.\"],\n) -> Annotated[str, \"Path of the saved outline file.\"]:\n    \"\"\"\n    Creates and saves an outline to a file.\n\n    result = create_outline([\"Introduction\", \"Methodology\", \"Results\", \"Conclusion\"], \"outline.txt\")\n\n    Args:\n        points (List[str]): A list of main points or sections.\n        file_name (str): The file path to save the outline.\n    Returns:\n        str: A confirmation message with the path of the saved outline file.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        for i, point in enumerate(points):\n            file.write(f\"{i + 1}. {point}\\n\")\n    return f\"Outline saved to {file_name}\"\n\n@tool\ndef read_document(\n    file_name: Annotated[str, \"File path to read the document from.\"],\n    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n) -> str:\n    \"\"\"\n    Reads the specified document from a file.\n\n    content = read_document(\"outline.txt\", start=0, end=2)\n\n    Args:\n        file_name (str): The file path to read the document from.\n        start (Optional[int]): The start line. Default is 0.\n        end (Optional[int]): The end line. Default is None.\n    Returns:\n        str: A string containing the specified lines from the document.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n        lines = file.readlines()\n    if start is not None:\n        start = 0\n    return \"\\n\".join(lines[start:end])\n\n@tool\ndef write_document(\n    content: Annotated[str, \"Text content to be written into the document.\"],\n    file_name: Annotated[str, \"File path to save the document.\"],\n) -> Annotated[str, \"Path of the saved document file.\"]:\n    \"\"\"\n    Writes content to a file.\n    Args:\n        content (str): The text content to write.\n        file_name (str): The file path to save the document.\n    Returns:\n        str: A confirmation message with the path of the saved document file.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        file.write(content)\n    return f\"Document saved to {file_name}\"\n\n@tool\ndef edit_document(\n    file_name: Annotated[str, \"Path of the document to be edited.\"],\n    inserts: Annotated[\n        Dict[int, str],\n        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n    ],\n) -> Annotated[str, \"Path of the edited document file.\"]:\n    \"\"\"\n    Edits a document by inserting text at specific line numbers.\n\n    result = edit_document(\"document.txt\", {2: \"This is an inserted line.\"})\n\n    Args:\n        file_name (str): The file path of the document to edit.\n        inserts (Dict[int, str]): A dictionary where keys are line numbers (1-indexed) and values are text to insert.\n    Returns:\n        str: A confirmation message with the path of the edited document file.\n    \"\"\"\n    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n        lines = file.readlines()\n    sorted_inserts = sorted(inserts.items())\n    for line_number, text in sorted_inserts:\n        if 1 <= line_number <= len(lines) + 1:\n            lines.insert(line_number - 1, text + \"\\n\")\n        else:\n            return f\"Error: Line number {line_number} is out of range.\"\n    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n        file.writelines(lines)\n    return f\"Document edited and saved to {file_name}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:07:29.284804Z","iopub.execute_input":"2025-01-15T06:07:29.285286Z","iopub.status.idle":"2025-01-15T06:07:29.321808Z","shell.execute_reply.started":"2025-01-15T06:07:29.285252Z","shell.execute_reply":"2025-01-15T06:07:29.320793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setting Up the Python REPL Tool\n\nThe Python REPL tool allows for the execution of Python code within the agents. This can be useful for generating charts or performing computations based on the scraped data.","metadata":{}},{"cell_type":"code","source":"# Warning: This executes code locally, which can be unsafe when not sandboxed\nrepl = PythonREPL()\n\n@tool\ndef python_repl_tool(\n    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n):\n    \"\"\"\n    Executes Python code using a REPL (Read-Eval-Print Loop).\n    Args:\n        code (str): The Python code to execute.\n    Returns:\n        str: A string containing the execution result or an error message.\n    \"\"\"\n    try:\n        result = repl.run(code)\n    except BaseException as e:\n        return f\"Failed to execute. Error: {repr(e)}\"\n    return f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:07:29.323179Z","iopub.execute_input":"2025-01-15T06:07:29.323505Z","iopub.status.idle":"2025-01-15T06:07:29.334264Z","shell.execute_reply.started":"2025-01-15T06:07:29.32347Z","shell.execute_reply":"2025-01-15T06:07:29.333025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining Helper Utilities\n\nWe define helper functions and utilities that assist in creating supervisor nodes and setting up the language model (LLM) for our agents.","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------------------------------------------------\n# Helper Utilities\n# --------------------------------------------------------------------------------------------------------\n\ndef make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n    \"\"\"\n    Creates a supervisor node that routes tasks to workers.\n\n    supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])\n\n    Args:\n        llm (BaseChatModel): A language model (e.g., ChatOpenAI).\n        members (list[str]): A list of worker names.\n    Returns:\n        str: A function (supervisor_node) that routes tasks to the appropriate worker.\n    \"\"\"\n    options = [\"FINISH\"] + members\n    system_prompt = (\n        \"You are a supervisor tasked with managing a conversation between the\"\n        f\" following workers: {members}. Given the following user request,\"\n        \" respond with the worker to act next. Each worker will perform a\"\n        \" task and respond with their results and status. When finished,\"\n        \" respond with FINISH.\"\n    )\n\n    class Router(TypedDict):\n        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n        next: str # Literal[ [\"FINISH\"] + members ]\n\n    def supervisor_node(state: MessagesState) -> Command[str]:  # Changed return type\n        \"\"\"\n        An LLM-based router.\n        Args:\n            state (MessagesState): The current state of the messages.\n        Returns:\n            Command[str]: A command indicating the next worker to route to.\n        \"\"\"\n        messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n        response = llm.with_structured_output(Router).invoke(messages)\n        goto = response[\"next\"]\n        if goto == \"FINISH\":\n            goto = END\n        return Command(goto=goto)\n\n    return supervisor_node","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:07:29.335599Z","iopub.execute_input":"2025-01-15T06:07:29.336027Z","iopub.status.idle":"2025-01-15T06:07:29.355772Z","shell.execute_reply.started":"2025-01-15T06:07:29.335986Z","shell.execute_reply":"2025-01-15T06:07:29.354626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fetching API Key\n\nThis cell retrieves the OpenAI API key stored in Kaggle Secrets and initializes the `ChatOpenAI` model with the fetched API key. The `UserSecretsClient` is used to securely fetch the key, ensuring the API key remains private.","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\n# Fetch the OpenAI API key from Kaggle secrets\nmy_api_key = UserSecretsClient().get_secret(\"my-openai-api-key\")\n\n# Initialize the ChatOpenAI model with the fetched API key\nllm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=my_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:11:14.325793Z","iopub.execute_input":"2025-01-15T06:11:14.326329Z","iopub.status.idle":"2025-01-15T06:11:14.677329Z","shell.execute_reply.started":"2025-01-15T06:11:14.326292Z","shell.execute_reply":"2025-01-15T06:11:14.676364Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setting Up the Research Team\n\nThe Research Team is responsible for searching the web and scraping relevant information. We create agents for searching and web scraping, define their respective nodes, and compile them into a state graph.","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------------------------------------------------\n# Research Team\n# --------------------------------------------------------------------------------------------------------\n\n# Create a search agent using the LLM and the search tool\nsearch_agent = create_react_agent(llm, tools=[search_tool])\n\ndef search_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Executes the search agent and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    result = search_agent.invoke(state)\n    print(\">>> search_node >>>\")\n    print(result[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< search_node <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n            ]\n        },\n        # Always route back to the supervisor after completing the task\n        goto=\"supervisor\",\n    )\n\n# Create a web scraper agent using the LLM and the scrape_webpages tool\nweb_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n\ndef web_scraper_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Executes the web scraper agent and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    result = web_scraper_agent.invoke(state)\n    print(\">>> web_scraper_node >>>\")\n    print(result[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< web_scraper_node <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n            ]\n        },\n        # Always route back to the supervisor after completing the task\n        goto=\"supervisor\",\n    )\n\n# Create a supervisor node for the research team\nresearch_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])\n\n# Build the research team state graph\nresearch_builder = StateGraph(MessagesState)\nresearch_builder.add_node(\"supervisor\", research_supervisor_node)  # Add supervisor node\nresearch_builder.add_node(\"search\", search_node)  # Add search node\nresearch_builder.add_node(\"web_scraper\", web_scraper_node)  # Add web scraper node\n\nresearch_builder.add_edge(START, \"supervisor\")  # Start with the supervisor\nresearch_graph = research_builder.compile()  # Compile the graph\n\n# Display the research team workflow as a Mermaid diagram\ndisplay(Image(research_graph.get_graph().draw_mermaid_png()))\n\n# Stream the research team workflow with a user query\nfor s in research_graph.stream(\n    {\"messages\": [(\"user\", \"when is Taylor Swift's next tour?\")]},\n    {\"recursion_limit\": 100},  # Limit recursion to prevent infinite loops\n):\n    print(s)  # Print the state at each step\n    print(\"-\" * 60)  # Separator for readability","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:11:14.678774Z","iopub.execute_input":"2025-01-15T06:11:14.67908Z","iopub.status.idle":"2025-01-15T06:11:26.914817Z","shell.execute_reply.started":"2025-01-15T06:11:14.679052Z","shell.execute_reply":"2025-01-15T06:11:26.913531Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setting Up the Document Writing Team\n\nThe Document Writing Team handles creating, reading, editing, and writing documents based on outlines. Additionally, it can generate charts by executing Python code. We create agents for document writing, note-taking, and chart generation, define their nodes, and compile them into a state graph.\n\n### **Document Writing Team Setup**\nThis block defines the **document writer agent**, which is responsible for reading, writing, and editing documents based on outlines provided by the note-taker. It uses an LLM (Large Language Model) and tools like `write_document`, `edit_document`, and `read_document`. The `doc_writing_node` function executes the agent, prints the result for debugging, and routes the output back to the supervisor.","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------------------------------------------------\n# Document Writing Team\n# --------------------------------------------------------------------------------------------------------\n\n# Create a document writer agent using the LLM and document-related tools\ndoc_writer_agent = create_react_agent(\n    llm,\n    tools=[write_document, edit_document, read_document],\n    state_modifier=(\n        \"You can read, write and edit documents based on note-taker's outlines. \"\n        \"Don't ask follow-up questions.\"\n    ),\n)\n\ndef doc_writing_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Executes the document writer agent and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    result = doc_writer_agent.invoke(state)\n    print(\">>> doc_writing_node >>>\")\n    print(result[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< doc_writing_node <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n            ]\n        },\n        # Always route back to the supervisor after completing the task\n        goto=\"supervisor\",\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:11:26.916615Z","iopub.execute_input":"2025-01-15T06:11:26.916909Z","iopub.status.idle":"2025-01-15T06:12:18.30286Z","shell.execute_reply.started":"2025-01-15T06:11:26.916886Z","shell.execute_reply":"2025-01-15T06:12:18.301518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Note-Taking Agent Setup**\nThis block defines the **note-taking agent**, which is responsible for reading documents and creating outlines for the document writer. It uses tools like `create_outline` and `read_document`. The `note_taking_node` function executes the agent, prints the result for debugging, and routes the output back to the supervisor.","metadata":{}},{"cell_type":"code","source":"# Create a note-taking agent using the LLM and outline-related tools\nnote_taking_agent = create_react_agent(\n    llm,\n    tools=[create_outline, read_document],\n    state_modifier=(\n        \"You can read documents and create outlines for the document writer. \"\n        \"Don't ask follow-up questions.\"\n    ),\n)\n\ndef note_taking_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Executes the note-taking agent and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    result = note_taking_agent.invoke(state)\n    print(\">>> note_taking_node >>>\")\n    print(result[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< note_taking_node <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n            ]\n        },\n        # Always route back to the supervisor after completing the task\n        goto=\"supervisor\",\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Chart-Generating Agent Setup**\nThis block defines the **chart-generating agent**, which is responsible for generating charts using the LLM and a Python REPL tool. It can also read documents. The `chart_generating_node` function executes the agent, prints the result for debugging, and routes the output back to the supervisor. Additionally, a **supervisor node** is created to manage the interactions between the document writer, note-taker, and chart generator.","metadata":{}},{"cell_type":"code","source":"# Create a chart-generating agent using the LLM and Python REPL tool\nchart_generating_agent = create_react_agent(\n    llm, tools=[read_document, python_repl_tool]\n)\n\ndef chart_generating_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Executes the chart-generating agent and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    result = chart_generating_agent.invoke(state)\n    print(\">>> chart_generating_node >>>\")\n    print(result[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< chart_generating_node <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(\n                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n                )\n            ]\n        },\n        # Always route back to the supervisor after completing the task\n        goto=\"supervisor\",\n    )\n\n# Create a supervisor node for the document writing team\ndoc_writing_supervisor_node = make_supervisor_node(\n    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **State Graph Construction and Execution**\nThis block builds the **state graph** for the document writing team workflow. It adds nodes for the supervisor, document writer, note-taker, and chart generator. The workflow starts with the supervisor and routes tasks to the appropriate agents. The graph is compiled, and a Mermaid diagram is displayed to visualize the workflow. Finally, the workflow is executed with a user query (e.g., \"Write an outline for a poem about cats and then write the poem to disk\"), and the state is printed at each step for debugging.","metadata":{}},{"cell_type":"code","source":"# Build the document writing team state graph\npaper_writing_builder = StateGraph(MessagesState)\npaper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)  # Add supervisor node\npaper_writing_builder.add_node(\"doc_writer\", doc_writing_node)  # Add document writer node\npaper_writing_builder.add_node(\"note_taker\", note_taking_node)  # Add note-taker node\npaper_writing_builder.add_node(\"chart_generator\", chart_generating_node)  # Add chart generator node\n\npaper_writing_builder.add_edge(START, \"supervisor\")  # Start with the supervisor\npaper_writing_graph = paper_writing_builder.compile()  # Compile the graph\n\n# Display the document writing team workflow as a Mermaid diagram\ndisplay(Image(paper_writing_graph.get_graph().draw_mermaid_png()))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stream the document writing team workflow with a user query\nfor s in paper_writing_graph.stream(\n    {\n        \"messages\": [\n            (\n                \"user\",\n                \"Write an outline for poem about cats and then write the poem to disk.\",\n            )\n        ]\n    },\n    {\"recursion_limit\": 100},  # Limit recursion to prevent infinite loops\n):\n    print(s)  # Print the state at each step\n    print(\"-\" * 60)  # Separator for readability","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Composing Teams into a Hierarchical Structure\n\nTo manage multiple teams effectively, we create a top-level supervisor that oversees both the Research Team and the Document Writing Team. This hierarchical structure allows for better task distribution and management.","metadata":{}},{"cell_type":"code","source":"# --------------------------------------------------------------------------------------------------------\n# Add Layers\n# --------------------------------------------------------------------------------------------------------\n\n# Create a supervisor node for the combined teams\nteams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])\n\ndef call_research_team(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Calls the research team and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n    print(\">>> call_research_team >>>\")\n    print(response[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< call_research_team <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(\n                    content=response[\"messages\"][-1].content, name=\"research_team\"\n                )\n            ]\n        },\n        goto=\"supervisor\",\n    )\n\ndef call_paper_writing_team(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n    \"\"\"\n    Calls the document writing team and returns the result to the supervisor.\n    Args:\n        state (MessagesState): The current state of the messages.\n    Returns:\n        Command[Literal[\"supervisor\"]]: A command to update the state and route to the supervisor.\n    \"\"\"\n    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n    print(\">>> call_paper_writing_team >>>\")\n    print(response[\"messages\"][-1].content)  # Print the latest message content for debugging\n    print(\"<<< call_paper_writing_team <<<\")\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(\n                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n                )\n            ]\n        },\n        goto=\"supervisor\",\n    )\n\n# Build the combined teams state graph\nsuper_builder = StateGraph(MessagesState)\nsuper_builder.add_node(\"supervisor\", teams_supervisor_node)  # Add supervisor node\nsuper_builder.add_node(\"research_team\", call_research_team)  # Add research team node\nsuper_builder.add_node(\"writing_team\", call_paper_writing_team)  # Add writing team node\n\nsuper_builder.add_edge(START, \"supervisor\")  # Start with the supervisor\nsuper_graph = super_builder.compile()  # Compile the graph\n\n# Display the combined teams workflow as a Mermaid diagram\ndisplay(Image(super_graph.get_graph().draw_mermaid_png()))\n\n# Stream the combined teams workflow with a user query\nfor s in super_graph.stream(\n    {\n        \"messages\": [\n            (\"user\", \"Research AI agents and write a brief report about them.\")\n        ],\n    },\n    {\"recursion_limit\": 150},  # Limit recursion to prevent infinite loops\n):\n    print(s)  # Print the state at each step\n    print(\"-\" * 60)  # Separator for readability","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T06:12:18.304451Z","iopub.execute_input":"2025-01-15T06:12:18.304875Z","iopub.status.idle":"2025-01-15T06:14:00.977867Z","shell.execute_reply.started":"2025-01-15T06:12:18.304835Z","shell.execute_reply":"2025-01-15T06:14:00.976675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nBy organizing agents into hierarchical teams with supervisors at different levels, we can efficiently manage complex tasks and a large number of workers. This structure enhances scalability and maintainability, allowing for more sophisticated and organized workflows in AI-driven applications.","metadata":{}}]}