{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to Create Tool-Enabled Agents Using LangGraph and LangChain\n\n## **Introduction**\n\nIn the rapidly evolving world of AI and natural language processing, building intelligent agents that can interact with tools and external systems is becoming increasingly important. LangGraph, a powerful framework for creating graph-based workflows, provides a seamless way to integrate tools and language models into agent-based systems. This article explores how key components—`langgraph.prebuilt.ToolNode`, `langchain_community.agent_toolkits.load_tools`, and `langchain.tools.StructuredTool`—work together with `langgraph.prebuilt.create_react_agent` to create dynamic, tool-enabled agents. By understanding these building blocks, developers can design agents that leverage external tools, manage complex workflows, and deliver structured outputs, unlocking new possibilities for intelligent automation.\n\n### **Comparison Table**\n\n| Feature/Class               | `ToolNode`                          | `load_tools`                        | `StructuredTool.from_function`       |\n|-----------------------------|-------------------------------------|-------------------------------------|--------------------------------------|\n| **Purpose**                 | Executes tools in a graph node      | Loads predefined tools by name      | Converts a function into a tool      |\n| **Tool Integration**        | Yes                                 | Yes                                 | Yes                                  |\n| **Custom Tools**            | Supported                           | No                                  | Yes                                  |\n| **Error Handling**          | Yes                                 | No                                  | No                                   |\n| **LLM Integration**         | Optional                            | Optional                            | No                                   |\n| **Use Case**                | Executing tools in a workflow       | Loading prebuilt tools              | Creating custom tools                |","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\n\nThis section installs the necessary Python libraries for working with LangChain, OpenAI, Anthropic, DuckDuckGo, Arxiv, GraphQL, and other utilities. These libraries include:\n\n- **`langchain-openai`**: Provides integration with OpenAI's language models and APIs, enabling the use of models like GPT-4 for natural language tasks.\n- **`langchain-anthropic`**: Enables integration with Anthropic's models (e.g., Claude) for advanced language processing and reasoning.\n- **`langchain_community`**: Contains community-contributed modules and tools for LangChain, including additional utilities and integrations.\n- **`langchain_experimental`**: Includes experimental features and utilities for LangChain, offering cutting-edge capabilities for advanced use cases.\n- **`langgraph`**: A library for building and visualizing graph-based workflows in LangChain, essential for creating tool-enabled agents and complex workflows.\n- **`duckduckgo-search`**: Enables programmatic access to DuckDuckGo's search functionality, allowing agents to retrieve real-time information from the web.\n- **`arxiv`**: Provides access to the Arxiv API, enabling agents to search and retrieve scientific papers and research articles.\n- **`httpx` and `gql`**: Libraries for making HTTP requests and interacting with GraphQL APIs, essential for integrating GraphQL-based tools and services.\n\nThese libraries form the foundation for building intelligent agents that can interact with external tools, retrieve information, and execute complex workflows.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU duckduckgo-search\n!pip install -qU arxiv\n!pip install -qU httpx gql # graphql","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:41:40.189888Z","iopub.execute_input":"2025-01-22T14:41:40.190249Z","iopub.status.idle":"2025-01-22T14:42:15.581883Z","shell.execute_reply.started":"2025-01-22T14:41:40.190224Z","shell.execute_reply":"2025-01-22T14:42:15.580526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initializing OpenAI and Anthropic Chat Models\nThis section demonstrates how to securely fetch API keys for OpenAI and Anthropic using Kaggle's `UserSecretsClient` and initialize their respective chat models. The `ChatOpenAI` and `ChatAnthropic` classes are used to create instances of these models, which can be used for natural language processing tasks such as text generation and conversational AI.\n\n**Key steps:**\n1. **Fetch API Keys**: The OpenAI and Anthropic API keys are securely retrieved using Kaggle's `UserSecretsClient`.\n2. **Initialize Chat Models**:\n   - The `ChatOpenAI` class is initialized with the `gpt-4o-mini` model and the fetched OpenAI API key.\n   - The `ChatAnthropic` class is initialized with the `claude-3-5-sonnet-latest` model and the fetched Anthropic API key.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_anthropic import ChatAnthropic\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key securely\nuser_secrets = UserSecretsClient()\n\n# Initialize LLM\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=user_secrets.get_secret(\"my-openai-api-key\"))\n#model = ChatAnthropic(model=\"claude-3-5-sonnet-latest\", temperature=0, api_key=user_secrets.get_secret(\"my-anthropic-api-key\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:25:48.732466Z","iopub.execute_input":"2025-01-22T14:25:48.732861Z","iopub.status.idle":"2025-01-22T14:25:51.694993Z","shell.execute_reply.started":"2025-01-22T14:25:48.732822Z","shell.execute_reply":"2025-01-22T14:25:51.694002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\ndef pretty_print(step):\n    \"\"\"\n    Pretty prints the `step` output as formatted JSON.\n    \n    Args:\n        step: The step output from the agent's stream.\n    \"\"\"\n    # Convert the step to a JSON string with indentation\n    step_json = json.dumps(step, indent=4, default=str)\n    print(step_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:58:57.941651Z","iopub.execute_input":"2025-01-22T14:58:57.942067Z","iopub.status.idle":"2025-01-22T14:58:57.946811Z","shell.execute_reply.started":"2025-01-22T14:58:57.942037Z","shell.execute_reply":"2025-01-22T14:58:57.94565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Tool Integration**\n\n### **`ToolNode` class**\nThis class represents a node in a graph that executes tools based on the tool calls in the last `AIMessage`. It runs tools in parallel if multiple tool calls are requested.\n\n**Key Features**:\n- Executes tools dynamically based on LLM tool calls.\n- Handles tool errors gracefully.\n- Can be integrated into a `StateGraph` for complex workflows.","metadata":{}},{"cell_type":"code","source":"from langchain_core.messages import AIMessage\nfrom langchain_core.tools import tool\nfrom langgraph.prebuilt import ToolNode\n\n@tool\ndef check_weather(location: str) -> str:\n    \"\"\"Call to check the current weather.\"\"\"\n    return f\"It's always sunny in {location}\"\n\ntool_node = ToolNode(tools=[check_weather])\n\nmessage_with_single_tool_call = AIMessage(\n    content=\"\",\n    tool_calls=[\n        {\n            \"name\": \"check_weather\",\n            \"args\": {\"location\": \"sf\"},\n            \"id\": \"tool_call_id\",\n            \"type\": \"tool_call\",\n        }\n    ],\n)\n\nresult = tool_node.invoke({\"messages\": [message_with_single_tool_call]})\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:31:26.850082Z","iopub.execute_input":"2025-01-22T14:31:26.850513Z","iopub.status.idle":"2025-01-22T14:31:26.864646Z","shell.execute_reply.started":"2025-01-22T14:31:26.85047Z","shell.execute_reply":"2025-01-22T14:31:26.863692Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **`load_tools` function**\nThis function loads predefined tools by their names. These tools allow agents to interact with external resources like APIs, databases, and file systems.\n\n**Key Features**:\n- Loads tools dynamically based on their names.\n- Supports optional LLM integration for certain tools.\n- Allows enabling dangerous tools (e.g., tools with elevated permissions) with caution.","metadata":{}},{"cell_type":"code","source":"from langchain_community.agent_toolkits.load_tools import load_tools\n\n# Load tools\ntools = load_tools([\"ddg-search\", \"graphql\", \"arxiv\"], \n                   llm=model, \n                   graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\")\nprint(tools)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:22:34.702331Z","iopub.execute_input":"2025-01-22T15:22:34.702746Z","iopub.status.idle":"2025-01-22T15:22:34.709518Z","shell.execute_reply.started":"2025-01-22T15:22:34.702714Z","shell.execute_reply":"2025-01-22T15:22:34.708288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **`StructuredTool` class**\nThis method creates a custom tool from a Python function. It is useful for defining tools with specific input and output schemas.\n\n**Key Features**:\n- Converts a function into a tool with a name, description, and schema.\n- Supports both synchronous and asynchronous functions.\n- Can infer schemas from function signatures and docstrings.","metadata":{}},{"cell_type":"code","source":"from langchain_core.tools.structured import StructuredTool\n\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    return a + b\n\ntool = StructuredTool.from_function(add)\n\n# Correct way: Pass arguments as a dictionary\nresult = tool.run({\"a\": 1, \"b\": 2})\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:47:50.860158Z","iopub.execute_input":"2025-01-22T14:47:50.86053Z","iopub.status.idle":"2025-01-22T14:47:50.874144Z","shell.execute_reply.started":"2025-01-22T14:47:50.8605Z","shell.execute_reply":"2025-01-22T14:47:50.873037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Using Built-In Tools**\n\n### **Example 1: Basic Agent with DuckDuckGo and Arxiv**\n\nThis example demonstrates how to create a basic agent that uses built-in tools like **DuckDuckGo Search** and **Arxiv** to search for information and summarize results. The agent is initialized with a language model (LLM) and a `ToolNode` that wraps the tools for execution.","metadata":{}},{"cell_type":"code","source":"from langchain_community.agent_toolkits.load_tools import load_tools\nfrom langgraph.prebuilt import ToolNode, create_react_agent\n\n# Step 1: Load tools\ntools = load_tools([\"ddg-search\", \"arxiv\"], llm=model)\n\n# Step 2: Create a ToolNode\ntool_node = ToolNode(tools=tools, name=\"tools\")\n\n# Step 3: Create a React Agent\nagent = create_react_agent(model, tool_node)\n\n# Step 4: Run the agent\ninputs = {\"messages\": [(\"user\", \"Search for recent papers on quantum computing and summarize the top result.\")]}\nfor step in agent.stream(inputs):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:25:01.548395Z","iopub.execute_input":"2025-01-22T15:25:01.5488Z","iopub.status.idle":"2025-01-22T15:25:09.836598Z","shell.execute_reply.started":"2025-01-22T15:25:01.548771Z","shell.execute_reply":"2025-01-22T15:25:09.835606Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 2: Interrupts and Checkpointing**\n\nThis example demonstrates how to add **interrupts** and **checkpointing** to the agent workflow. Interrupts allow the agent to pause execution before or after specific nodes (e.g., before executing tools), while checkpointing enables the agent to persist its state across interactions.","metadata":{}},{"cell_type":"code","source":"from langchain_community.agent_toolkits.load_tools import load_tools\nfrom langgraph.prebuilt import ToolNode, create_react_agent\nfrom langgraph.checkpoint.memory import MemorySaver\n\n# Step 1: Load tools and create ToolNode\ntools = load_tools([\"ddg-search\", \"arxiv\", \"graphql\"], \n                   llm=model, \n                   graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\")\ntool_node = ToolNode(tools=tools, name=\"tools\")\n\n# Step 2: Create a React Agent with interrupts and checkpointing\nagent = create_react_agent(\n    model,\n    tool_node,\n    interrupt_before=[\"tools\"],  # Pause before executing tools\n    checkpointer=MemorySaver()   # Enable checkpointing for chat memory\n)\n\n# Step 3: Run the agent\ninputs = {\"messages\": [(\"user\", \"Search for recent papers on quantum computing and summarize the top result.\")]}\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\"}}\nfor step in agent.stream(inputs, config):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:27:54.26831Z","iopub.execute_input":"2025-01-22T15:27:54.268729Z","iopub.status.idle":"2025-01-22T15:27:55.269354Z","shell.execute_reply.started":"2025-01-22T15:27:54.268695Z","shell.execute_reply":"2025-01-22T15:27:55.268348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 3: Cross-Thread Memory**\n\nThis example introduces **cross-thread memory** using an `InMemoryStore`. The store allows the agent to persist data across multiple threads or conversations, enabling features like user-specific memory or shared context.","metadata":{}},{"cell_type":"code","source":"from langchain_community.agent_toolkits.load_tools import load_tools\nfrom langgraph.prebuilt import ToolNode, create_react_agent\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.store.memory import InMemoryStore\n\n# Step 1: Define a memory store\nstore = InMemoryStore()\n\n# Step 2: Load tools and create ToolNode\ntools = load_tools([\"ddg-search\", \"arxiv\", \"graphql\"], \n                   llm=model, \n                   graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\")\ntool_node = ToolNode(tools=tools, name=\"tools\")\n\n# Step 3: Create a React Agent with cross-thread memory\nagent = create_react_agent(\n    model,\n    tool_node,\n    store=store,\n    checkpointer=MemorySaver()\n)\n\n# Step 4: Run the agent\ninputs = {\"messages\": [(\"user\", \"Search for recent papers on quantum computing and summarize the top result.\")]}\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\", \"user_id\": \"123\"}}\nfor step in agent.stream(inputs, config):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:28:08.06372Z","iopub.execute_input":"2025-01-22T15:28:08.064227Z","iopub.status.idle":"2025-01-22T15:28:13.933154Z","shell.execute_reply.started":"2025-01-22T15:28:08.064192Z","shell.execute_reply":"2025-01-22T15:28:13.932047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 4: Complex Prompt and State Modifier**\n\nThis example demonstrates how to use a **state modifier** to customize the input to the LLM. A `ChatPromptTemplate` is used to define a complex prompt, and a state modifier function dynamically prepares the input for the LLM.","metadata":{}},{"cell_type":"code","source":"from langchain_community.agent_toolkits.load_tools import load_tools\nfrom langgraph.prebuilt import ToolNode, create_react_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# Step 1: Define a state modifier\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant named Fred.\"),\n    (\"placeholder\", \"{messages}\"),\n    (\"user\", \"Remember to be polite!\"),\n])\n\ndef state_modifier(state):\n    return prompt.invoke({\"messages\": state[\"messages\"]})\n\n# Step 2: Load tools and create ToolNode\ntools = load_tools([\"ddg-search\", \"arxiv\", \"graphql\"], \n                   llm=model, \n                   graphql_endpoint=\"https://swapi-graphql.netlify.app/.netlify/functions/index\")\ntool_node = ToolNode(tools=tools, name=\"tools\")\n\n# Step 3: Create a React Agent with state modifier\nagent = create_react_agent(\n    model,\n    tool_node,\n    state_modifier=state_modifier\n)\n\n# Step 4: Run the agent\ninputs = {\"messages\": [(\"user\", \"Search for recent papers on quantum computing and summarize the top result.\")]}\nfor step in agent.stream(inputs):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:28:21.617101Z","iopub.execute_input":"2025-01-22T15:28:21.617486Z","iopub.status.idle":"2025-01-22T15:28:27.642965Z","shell.execute_reply.started":"2025-01-22T15:28:21.617455Z","shell.execute_reply":"2025-01-22T15:28:27.64188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Using Custom Tools**\n\n### **Example 1: Basic Agent with Custom Tools**\n\nThis example demonstrates how to create a basic agent using custom tools. We define three custom tools (`get_current_time`, `calculate_tip`, and `get_weather`) using `StructuredTool.from_function`. These tools are then wrapped in a `ToolNode` and integrated into a `create_react_agent` workflow. The agent is initialized with an OpenAI GPT-4 model and processes user queries by dynamically calling the appropriate tool.","metadata":{}},{"cell_type":"code","source":"from langchain_core.tools.structured import StructuredTool\nfrom datetime import datetime\nimport pytz\n\n# Tool 1: Get current time in a specified timezone\ndef get_current_time(timezone: str) -> str:\n    \"\"\"Returns the current time in the specified timezone.\"\"\"\n    tz = pytz.timezone(timezone)\n    current_time = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n    return f\"The current time in {timezone} is {current_time}.\"\n\n# Tool 2: Calculate tip amount\ndef calculate_tip(bill_total: float, tip_percentage: float) -> str:\n    \"\"\"Calculates the tip amount for a given bill total and tip percentage.\"\"\"\n    tip_amount = bill_total * (tip_percentage / 100)\n    total_amount = bill_total + tip_amount\n    return f\"Tip: ${tip_amount:.2f}, Total: ${total_amount:.2f}\"\n\n# Tool 3: Get weather for a location (simulated)\ndef get_weather(location: str) -> str:\n    \"\"\"Simulates fetching the weather for a given location.\"\"\"\n    return f\"The weather in {location} is sunny with a high of 75°F.\"\n\n# Create StructuredTool instances\ntime_tool = StructuredTool.from_function(get_current_time)\ntip_tool = StructuredTool.from_function(calculate_tip)\nweather_tool = StructuredTool.from_function(get_weather)\n\n# Combine tools into a list\ntools = [time_tool, tip_tool, weather_tool]\n\n# Create a ToolNode\nfrom langgraph.prebuilt import ToolNode\ntool_node = ToolNode(tools=tools, name=\"tools\")\n\n# Create a React Agent\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_openai import ChatOpenAI\n\n# Create the agent\nagent = create_react_agent(model, tool_node)\n\n# Run the agent\ninputs = {\"messages\": [(\"user\", \"What's the current time in New York?\")]}\nfor step in agent.stream(inputs):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:58:26.236344Z","iopub.execute_input":"2025-01-22T14:58:26.236908Z","iopub.status.idle":"2025-01-22T14:58:28.657273Z","shell.execute_reply.started":"2025-01-22T14:58:26.236868Z","shell.execute_reply":"2025-01-22T14:58:28.656283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 2: Interrupts and Checkpointing**\n\nThis example demonstrates how to add **interrupts** and **checkpointing** to the agent workflow. Interrupts allow the agent to pause execution before or after specific nodes (e.g., before executing tools), enabling user confirmation or additional processing. Checkpointing, using `MemorySaver`, persists the state of the agent across interactions, enabling features like chat memory. This example is ideal for building interactive and stateful conversational agents.","metadata":{}},{"cell_type":"code","source":"from langgraph.prebuilt import create_react_agent\nfrom langgraph.checkpoint.memory import MemorySaver\n\n# Create the agent with interrupts and checkpointing\nagent = create_react_agent(\n    model,\n    tool_node,\n    interrupt_before=[\"tools\"],  # Pause before executing tools\n    checkpointer=MemorySaver()   # Enable checkpointing for chat memory\n)\n\n# Run the agent\ninputs = {\"messages\": [(\"user\", \"What's the weather in San Francisco?\")]}\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\"}}\nfor step in agent.stream(inputs, config):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:14:39.312893Z","iopub.execute_input":"2025-01-22T15:14:39.313264Z","iopub.status.idle":"2025-01-22T15:14:40.127362Z","shell.execute_reply.started":"2025-01-22T15:14:39.313231Z","shell.execute_reply":"2025-01-22T15:14:40.126356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 3: Cross-Thread Memory**\n\nThis example introduces **cross-thread memory** using an `InMemoryStore`. The store allows the agent to persist data across multiple threads or conversations, enabling features like user-specific memory or shared context. The agent retrieves and updates user memories dynamically, enhancing the conversational experience. This example is ideal for multi-user or multi-session applications.","metadata":{}},{"cell_type":"code","source":"from langgraph.store.memory import InMemoryStore\n\n# Create a memory store\nstore = InMemoryStore()\n\n# Create a React Agent with Cross-Thread Memory\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.checkpoint.memory import MemorySaver\n\n# Create the agent with cross-thread memory\nagent = create_react_agent(\n    model,\n    tool_node,\n    store=store,\n    checkpointer=MemorySaver()\n)\n\n# Run the agent\ninputs = {\"messages\": [(\"user\", \"What's the current time in London?\")]}\nconfig = {\"configurable\": {\"thread_id\": \"thread-1\", \"user_id\": \"123\"}}\nfor step in agent.stream(inputs, config):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:15:07.066057Z","iopub.execute_input":"2025-01-22T15:15:07.066395Z","iopub.status.idle":"2025-01-22T15:15:09.200385Z","shell.execute_reply.started":"2025-01-22T15:15:07.066371Z","shell.execute_reply":"2025-01-22T15:15:09.198946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Example 4: Complex Prompt and State Modifier**\n\nThis example demonstrates how to use a **state modifier** to customize the input to the LLM. A `ChatPromptTemplate` is used to define a complex prompt, and a state modifier function dynamically prepares the input for the LLM. This approach is useful for adding system prompts, contextual instructions, or other modifications to the agent's behavior. The example shows how to integrate a state modifier into the agent workflow.","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import ChatPromptTemplate\n\n# Define a prompt template\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant named Fred.\"),\n    (\"placeholder\", \"{messages}\"),\n    (\"user\", \"Remember to be polite!\"),\n])\n\n# Define a state modifier\ndef state_modifier(state):\n    return prompt.invoke({\"messages\": state[\"messages\"]})\n\n# Create a React Agent with State Modifier\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_openai import ChatOpenAI\n\n# Create the agent with a state modifier\nagent = create_react_agent(\n    model,\n    tool_node,\n    state_modifier=state_modifier\n)\n\n# Run the agent\ninputs = {\"messages\": [(\"user\", \"What's the weather in Tokyo?\")]}\nfor step in agent.stream(inputs):\n    pretty_print(step)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T15:15:24.64625Z","iopub.execute_input":"2025-01-22T15:15:24.646635Z","iopub.status.idle":"2025-01-22T15:15:25.851602Z","shell.execute_reply.started":"2025-01-22T15:15:24.646598Z","shell.execute_reply":"2025-01-22T15:15:25.850446Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## **Conclusion**\n\nThe integration of `ToolNode`, `load_tools`, and `StructuredTool` with `create_react_agent` provides a robust foundation for building intelligent agents that can interact with tools and external systems. These components enable developers to create agents that are not only capable of understanding and generating natural language but also of executing tasks, retrieving information, and delivering structured responses. Whether you're building a conversational assistant, a research tool, or an automation workflow, understanding how these objects work together empowers you to design sophisticated, tool-enabled agents that can handle real-world challenges. As AI continues to advance, mastering these tools will be key to unlocking the full potential of intelligent systems.","metadata":{}}]}