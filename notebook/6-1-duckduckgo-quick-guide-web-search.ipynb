{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LangChain Built-in Tool: DuckDuckGo (Web Search)\n\n## Introduction\n\n`DuckDuckGoSearchRun` is a powerful tool within the LangChain framework that integrates DuckDuckGo's search functionality into your applications. Designed for developers and AI practitioners, this tool allows you to perform web searches programmatically, retrieve real-time information, and integrate search results into your workflows. Whether you're building chatbots, research assistants, or data pipelines, `DuckDuckGoSearchRun` provides a seamless way to access up-to-date information from the web without compromising user privacy, as DuckDuckGo is known for its privacy-first approach.\n\nThe tool is highly customizable, supporting features like retries, fallbacks, and configurable alternatives, making it robust and adaptable to various use cases. With its simple API and integration into the LangChain ecosystem, `DuckDuckGoSearchRun` is an essential component for applications that require dynamic, real-time data retrieval.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Preparation\n\n### Installing Required Libraries\nThis section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, Anthropic models, DuckDuckGo search, and other utilities. These libraries include:\n- `langchain-openai`: Provides integration with OpenAI's embedding models and APIs.\n- `langchain-anthropic`: Enables integration with Anthropic's models and APIs.\n- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n- `langgraph`: A library for building and visualizing graph-based workflows in LangChain.\n- `duckduckgo-search`: Enables programmatic access to DuckDuckGo's search functionality.","metadata":{}},{"cell_type":"code","source":"!pip install -qU langchain-openai\n!pip install -qU langchain-anthropic\n!pip install -qU langchain_community\n!pip install -qU langchain_experimental\n!pip install -qU langgraph\n!pip install -qU duckduckgo-search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:02:00.613887Z","iopub.execute_input":"2025-01-21T11:02:00.614301Z","iopub.status.idle":"2025-01-21T11:02:49.198934Z","shell.execute_reply.started":"2025-01-21T11:02:00.614272Z","shell.execute_reply":"2025-01-21T11:02:49.197094Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initializing OpenAI and Anthropic Chat Models\nThis section demonstrates how to securely fetch API keys for OpenAI and Anthropic using Kaggle's `UserSecretsClient` and initialize their respective chat models. The `ChatOpenAI` and `ChatAnthropic` classes are used to create instances of these models, which can be used for natural language processing tasks such as text generation and conversational AI.\n\n**Key steps:**\n1. **Fetch API Keys**: The OpenAI and Anthropic API keys are securely retrieved using Kaggle's `UserSecretsClient`.\n2. **Initialize Chat Models**:\n   - The `ChatOpenAI` class is initialized with the `gpt-4o-mini` model and the fetched OpenAI API key.\n   - The `ChatAnthropic` class is initialized with the `claude-3-5-latest` model and the fetched Anthropic API key.","metadata":{}},{"cell_type":"code","source":"from langchain_openai import ChatOpenAI\nfrom langchain_anthropic import ChatAnthropic\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key securely\nuser_secrets = UserSecretsClient()\n\n# Initialize LLM\nmodel = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=user_secrets.get_secret(\"my-openai-api-key\"))\n#model = ChatAnthropic(model=\"claude-3-5-latest\", temperature=0, api_key=user_secrets.get_secret(\"my-anthropic-api-key\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:02:49.200845Z","iopub.execute_input":"2025-01-21T11:02:49.201199Z","iopub.status.idle":"2025-01-21T11:02:49.505706Z","shell.execute_reply.started":"2025-01-21T11:02:49.201169Z","shell.execute_reply":"2025-01-21T11:02:49.504319Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 1. Initialization and Setup\n\n### Example 1: Basic Initialization\nThis example demonstrates how to initialize the `DuckDuckGoSearchRun` tool with default settings.**","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the DuckDuckGoSearchRun tool\ntool = DuckDuckGoSearchRun()\n\n# Example usage\nresult = tool.invoke(\"Python programming\")\n\nword_count = len(result.split())\nprint(\"Number of words:\", word_count)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:49:26.262738Z","iopub.execute_input":"2025-01-21T11:49:26.263106Z","iopub.status.idle":"2025-01-21T11:49:27.239679Z","shell.execute_reply.started":"2025-01-21T11:49:26.263077Z","shell.execute_reply":"2025-01-21T11:49:27.238574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Custom Initialization with Configuration\nThis example shows how to initialize the tool with custom configurations, such as setting a description and enabling verbose logging.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool with custom settings\ntool = DuckDuckGoSearchRun(\n    description=\"A custom DuckDuckGo search tool for finding programming resources.\",\n    verbose=True\n)\n\n# Example usage\nresult = tool.invoke(\"LangChain framework\")\n\nword_count = len(result.split())\nprint(\"\\nNumber of words:\", word_count)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:50:16.49662Z","iopub.execute_input":"2025-01-21T11:50:16.496997Z","iopub.status.idle":"2025-01-21T11:50:17.010993Z","shell.execute_reply.started":"2025-01-21T11:50:16.496969Z","shell.execute_reply":"2025-01-21T11:50:17.009926Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 2. Search Execution\n\n### Example 1: Simple Search Execution\nThis example demonstrates how to perform a simple search using the `invoke` method.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool\ntool = DuckDuckGoSearchRun()\n\n# Perform a search\nresult = tool.invoke(\"latest AI news\")\n\nword_count = len(result.split())\nprint(\"\\nNumber of words:\", word_count)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:51:09.409427Z","iopub.execute_input":"2025-01-21T11:51:09.409861Z","iopub.status.idle":"2025-01-21T11:51:10.092563Z","shell.execute_reply.started":"2025-01-21T11:51:09.409828Z","shell.execute_reply":"2025-01-21T11:51:10.091402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Search with ToolCall Input\nThis example shows how to use the tool with a `ToolCall` input, which is useful for structured inputs.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool\ntool = DuckDuckGoSearchRun()\n\n# Perform a search using ToolCall input\ntool_input = {\n    \"args\": {\"query\": \"machine learning trends 2023\"},\n    \"id\": \"1\",\n    \"name\": tool.name,\n    \"type\": \"tool_call\"\n}\nresult = tool.invoke(tool_input)\n\n# Access specific properties (if applicable)\nif hasattr(result, 'tool_call_id'):\n    print(\"Tool Call ID:\", result.tool_call_id)\nif hasattr(result, 'name'):\n    print(\"Name:\", result.name)\nif hasattr(result, 'content'):\n    print(\"Content:\", result.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:54:19.170638Z","iopub.execute_input":"2025-01-21T11:54:19.171014Z","iopub.status.idle":"2025-01-21T11:54:20.013213Z","shell.execute_reply.started":"2025-01-21T11:54:19.170986Z","shell.execute_reply":"2025-01-21T11:54:20.012065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 3. Streaming and Batch Processing\n\n### Example 1: Batch Processing\nThis example demonstrates how to process multiple search queries in batch mode.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool\ntool = DuckDuckGoSearchRun()\n\n# List of queries to process\nqueries = [\"Python programming\", \"machine learning\", \"data science\"]\n\n# Perform batch processing\nresults = tool.batch(queries)\nfor result in results:\n    print(result)\n    print(\"-\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:54:58.911955Z","iopub.execute_input":"2025-01-21T11:54:58.912286Z","iopub.status.idle":"2025-01-21T11:54:59.856784Z","shell.execute_reply.started":"2025-01-21T11:54:58.912261Z","shell.execute_reply":"2025-01-21T11:54:59.855628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Streaming Search Results\nThis example shows how to stream search results for a single query.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool\ntool = DuckDuckGoSearchRun()\n\n# Stream search results\nquery = \"latest AI news\"\nfor result in tool.stream(query):\n    print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:55:36.555291Z","iopub.execute_input":"2025-01-21T11:55:36.555701Z","iopub.status.idle":"2025-01-21T11:55:37.298913Z","shell.execute_reply.started":"2025-01-21T11:55:36.555672Z","shell.execute_reply":"2025-01-21T11:55:37.297431Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 4. Error Handling and Retries\n\n### Retry Configuration Parameters\n\n1. **`retry_if_exception_type`**:\n   - This parameter specifies the types of exceptions that should trigger a retry.\n   - In your example, `retry_if_exception_type=(Exception,)` means that **any exception** (since `Exception` is the base class for all exceptions in Python) will trigger a retry.\n\n2. **`stop_after_attempt`**:\n   - This parameter specifies the maximum number of retry attempts before giving up.\n   - In your example, `stop_after_attempt=3` means the tool will retry up to **3 times** (including the initial attempt) before raising the exception if it continues to fail.\n\n3. **`wait_exponential_jitter`** (not used in your example but worth mentioning):\n   - If enabled, this adds a random \"jitter\" (small delay) to the wait time between retries, which helps avoid thundering herd problems in distributed systems.\n   - The wait time between retries grows exponentially (e.g., 1s, 2s, 4s, etc.) with jitter added to avoid synchronized retries.\n\n### Example 1: Retry on Failure\nThis example demonstrates how to configure the tool to retry on specific exceptions.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool with retry configuration\ntool = DuckDuckGoSearchRun().with_retry(\n    retry_if_exception_type=(Exception,),  # Retry on any exception\n    stop_after_attempt=3                   # Retry up to 3 times\n)\n\n# Perform a search with retry logic\nresult = tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:55:55.939118Z","iopub.execute_input":"2025-01-21T11:55:55.93954Z","iopub.status.idle":"2025-01-21T11:55:56.745835Z","shell.execute_reply.started":"2025-01-21T11:55:55.939508Z","shell.execute_reply":"2025-01-21T11:55:56.74456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exponential Backoff with Jitter\ntool = DuckDuckGoSearchRun().with_retry(\n    retry_if_exception_type=(Exception,),\n    wait_exponential_jitter=True,  # Enable exponential backoff with jitter\n    stop_after_attempt=3\n)\n\n# Perform a search with retry logic\nresult = tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:59:30.043743Z","iopub.execute_input":"2025-01-21T11:59:30.044134Z","iopub.status.idle":"2025-01-21T11:59:31.013654Z","shell.execute_reply.started":"2025-01-21T11:59:30.044106Z","shell.execute_reply":"2025-01-21T11:59:31.012365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specific Exception Types:\n# If you only want to retry on specific exceptions (e.g., ConnectionError or TimeoutError), you can specify them.\ntool = DuckDuckGoSearchRun().with_retry(\n    retry_if_exception_type=(ConnectionError, TimeoutError),\n    stop_after_attempt=3\n)\n\n# Perform a search with retry logic\nresult = tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T11:59:34.439421Z","iopub.execute_input":"2025-01-21T11:59:34.439849Z","iopub.status.idle":"2025-01-21T11:59:35.177033Z","shell.execute_reply.started":"2025-01-21T11:59:34.439821Z","shell.execute_reply":"2025-01-21T11:59:35.176051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. How Fallbacks Work\n\n1. **Primary Tool**:\n   - The primary tool is the first tool in the sequence. In your example, this is the `DuckDuckGoSearchRun` instance (`primary_tool`).\n   - When you invoke the tool (e.g., `tool.invoke(\"Python programming\")`), the primary tool is executed first.\n\n2. **Fallback Tools**:\n   - If the primary tool fails (e.g., raises an exception), the fallback mechanism kicks in.\n   - The fallback tools are tried in the order they are specified in the `with_fallbacks` method. In your example, there is one fallback tool (`fallback_tool`), which is another instance of `DuckDuckGoSearchRun`.\n\n3. **Execution Flow**:\n   - The primary tool is executed first.\n   - If the primary tool succeeds, its result is returned, and the fallback tools are not used.\n   - If the primary tool fails, the first fallback tool is executed.\n   - If the first fallback tool fails, the next fallback tool is executed, and so on, until either:\n     - A tool succeeds and returns a result.\n     - All tools fail, and an exception is raised.\n\n4. **Exception Handling**:\n   - By default, if all tools fail, the exception from the last tool is raised.\n   - You can customize how exceptions are handled using the `exceptions_to_handle` and `exception_key` parameters in the `with_fallbacks` method (not shown in your example).\n\n### Example 2: Fallback on Failure\nThis example shows how to configure fallback behavior if the primary search fails.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the primary tool\nprimary_tool = DuckDuckGoSearchRun()\n\n# Initialize a fallback tool (e.g., another search tool or a mock response)\nfallback_tool = DuckDuckGoSearchRun(description=\"Fallback search tool\")\n\n# Configure the tool with fallbacks\ntool = primary_tool.with_fallbacks([fallback_tool])\n\n# Perform a search with fallback logic\nresult = tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:01:32.06343Z","iopub.execute_input":"2025-01-21T12:01:32.063845Z","iopub.status.idle":"2025-01-21T12:01:33.206532Z","shell.execute_reply.started":"2025-01-21T12:01:32.063815Z","shell.execute_reply":"2025-01-21T12:01:33.205508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the primary tool\nprimary_tool = DuckDuckGoSearchRun()\n\n# Initialize fallback tools\nfallback_tool_1 = DuckDuckGoSearchRun(description=\"Fallback tool 1\")\nfallback_tool_2 = DuckDuckGoSearchRun(description=\"Fallback tool 2\")\n\n# Configure the tool with multiple fallbacks\ntool = primary_tool.with_fallbacks([fallback_tool_1, fallback_tool_2])\n\n# Perform a search with fallback logic\nresult = tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:03:58.820279Z","iopub.execute_input":"2025-01-21T12:03:58.820688Z","iopub.status.idle":"2025-01-21T12:03:59.560315Z","shell.execute_reply.started":"2025-01-21T12:03:58.820653Z","shell.execute_reply":"2025-01-21T12:03:59.559235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## 6. Configuration and Binding\n\n### Example 1: Binding Additional Arguments\n\n#### Description\n**Binding** allows you to attach additional arguments or configurations to a tool, creating a new instance of the tool with those arguments pre-set. This is useful when you want to reuse a tool with specific settings without having to pass those settings every time you invoke the tool.\n\nIn this example:\n- The `DuckDuckGoSearchRun` tool is initialized.\n- The `bind` method is used to attach a custom argument (`query_filter=\"site:github.com\"`) to the tool.\n- The bound tool (`custom_tool`) is then invoked with a search query, and the custom argument is automatically applied.\n\n#### How It Works\n1. **Initialization**:\n   - The `DuckDuckGoSearchRun` tool is created with default settings.\n\n2. **Binding**:\n   - The `bind` method is called on the tool, passing the argument `query_filter=\"site:github.com\"`.\n   - This creates a new instance of the tool (`custom_tool`) with the `query_filter` argument pre-set.\n\n3. **Invocation**:\n   - When `custom_tool.invoke(\"Python programming\")` is called, the search query `\"Python programming\"` is combined with the bound argument `query_filter=\"site:github.com\"`.\n   - The tool performs the search, filtering results to only include those from `github.com`.\n\n4. **Output**:\n   - The search results are returned and printed.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\n\n# Initialize the tool\ntool = DuckDuckGoSearchRun()\n\n# Bind additional arguments (e.g., a custom search filter)\ncustom_tool = tool.bind(query_filter=\"site:github.com\")\n\n# Perform a search with the bound arguments\nresult = custom_tool.invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:05:05.137638Z","iopub.execute_input":"2025-01-21T12:05:05.138075Z","iopub.status.idle":"2025-01-21T12:05:05.794769Z","shell.execute_reply.started":"2025-01-21T12:05:05.138041Z","shell.execute_reply":"2025-01-21T12:05:05.79361Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Configurable Alternatives\n\n#### Description\n**Configurable alternatives** allow you to define multiple versions of a tool and switch between them at runtime. This is useful when you want to provide different implementations or behaviors for the same tool, depending on the context or configuration.\n\nIn this example:\n- A primary tool (`primary_tool`) and an alternative tool (`alternative_tool`) are initialized.\n- The `configurable_alternatives` method is used to configure the tool with these alternatives.\n- The tool can then be invoked using either the primary or alternative implementation, depending on the runtime configuration.\n\n#### How It Works\n1. **Initialization**:\n   - The primary tool (`primary_tool`) and an alternative tool (`alternative_tool`) are created.\n\n2. **Configuration**:\n   - The `configurable_alternatives` method is called on the primary tool, passing:\n     - A `ConfigurableField` instance with an `id` of `\"search_tool\"`.\n     - A `default_key` of `\"primary\"`, which specifies the default tool to use.\n     - An `alternative` tool (`alternative_tool`), which can be selected at runtime.\n\n3. **Default Invocation**:\n   - When `tool.invoke(\"Python programming\")` is called, the primary tool is used by default.\n\n4. **Alternative Invocation**:\n   - When `tool.with_config(configurable={\"search_tool\": \"alternative\"}).invoke(\"Python programming\")` is called, the alternative tool is used instead.\n\n5. **Output**:\n   - The search results from the selected tool are returned and printed.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_core.runnables.utils import ConfigurableField\n\n# Initialize the primary tool\nprimary_tool = DuckDuckGoSearchRun()\n\n# Initialize an alternative tool (e.g., a mock search tool)\nalternative_tool = DuckDuckGoSearchRun(description=\"Alternative search tool\")\n\n# Configure the tool with alternatives\ntool = primary_tool.configurable_alternatives(\n    ConfigurableField(id=\"search_tool\"),\n    default_key=\"primary\",\n    alternative=alternative_tool\n)\n\n# Perform a search using the default tool\nresult = tool.invoke(\"Python programming\")\nprint(result)\n\n# Perform a search using the alternative tool\nresult = tool.with_config(configurable={\"search_tool\": \"alternative\"}).invoke(\"Python programming\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:07:18.474731Z","iopub.execute_input":"2025-01-21T12:07:18.475107Z","iopub.status.idle":"2025-01-21T12:07:19.917361Z","shell.execute_reply.started":"2025-01-21T12:07:18.47508Z","shell.execute_reply":"2025-01-21T12:07:19.916002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## Best Practices\n\n### Example 1: Enhancing a Chatbot with Real-Time Web Search\nThis example demonstrates how to integrate `DuckDuckGoSearchRun` into a chatbot powered by a large language model (LLM) to provide real-time, up-to-date information. The chatbot can answer questions about current events, recent news, or any topic that requires live data from the web.\n\n#### Explanation\n1. **Search Tool Integration**:\n   - The `DuckDuckGoSearchRun` tool is used to perform real-time web searches.\n   - The search results are passed to the LLM as part of the input.\n\n2. **LLM Prompting**:\n   - The LLM is instructed to use the search results to provide accurate and up-to-date answers.\n\n3. **Output**:\n   - The chatbot combines the LLM's reasoning capabilities with real-time search results to answer user queries effectively.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# Initialize the DuckDuckGoSearchRun tool\nsearch_tool = DuckDuckGoSearchRun()\n\n# Define a prompt template for the chatbot\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant. Use the search tool to find up-to-date information if needed.\"),\n    (\"user\", \"{input}\")\n])\n\n# Create a chain that integrates the search tool and LLM\nchain = (\n    {\"input\": lambda x: x[\"input\"], \"search_results\": lambda x: search_tool.invoke(x[\"input\"])}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\n# Example usage\nresponse = chain.invoke({\"input\": \"What are the latest trends in AI for 2023?\"})\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:15:06.832098Z","iopub.execute_input":"2025-01-21T12:15:06.832536Z","iopub.status.idle":"2025-01-21T12:15:16.248837Z","shell.execute_reply.started":"2025-01-21T12:15:06.832501Z","shell.execute_reply":"2025-01-21T12:15:16.247723Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Example 2: Building a Research Assistant\nThis example shows how to create a research assistant that uses `DuckDuckGoSearchRun` to gather information on a specific topic and summarize it using an LLM. This is particularly useful for tasks like market research, academic studies, or competitive analysis.\n\n#### Explanation\n1. **Search Tool Integration**:\n   - The `DuckDuckGoSearchRun` tool is used to gather information on a specific topic (e.g., renewable energy trends in 2023).\n\n2. **LLM Summarization**:\n   - The search results are passed to the LLM, which summarizes the information into a concise and readable format.\n\n3. **Output**:\n   - The research assistant provides a well-structured summary of the latest information on the topic, making it easier for users to understand key insights.","metadata":{}},{"cell_type":"code","source":"from langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# Initialize the DuckDuckGoSearchRun tool\nsearch_tool = DuckDuckGoSearchRun()\n\n# Define a prompt template for summarization\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a research assistant. Summarize the following information:\"),\n    (\"user\", \"{search_results}\")\n])\n\n# Create a chain that integrates the search tool and LLM\nchain = (\n    {\"search_results\": lambda x: search_tool.invoke(x[\"topic\"])}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\n# Example usage\ntopic = \"renewable energy trends in 2023\"\nsummary = chain.invoke({\"topic\": topic})\nprint(f\"Summary for '{topic}':\\n{summary}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T12:15:31.046217Z","iopub.execute_input":"2025-01-21T12:15:31.046622Z","iopub.status.idle":"2025-01-21T12:15:37.247676Z","shell.execute_reply.started":"2025-01-21T12:15:31.046584Z","shell.execute_reply":"2025-01-21T12:15:37.246576Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## Conclusion\n\n`DuckDuckGoSearchRun` is a versatile and reliable tool for integrating web search capabilities into your applications. Its privacy-focused design, combined with LangChain's powerful features like retries, fallbacks, and configurable alternatives, makes it an excellent choice for developers building intelligent systems that require real-time information. Whether you're creating a chatbot, automating research tasks, or enhancing data pipelines, `DuckDuckGoSearchRun` provides the flexibility and robustness needed to handle dynamic search requirements.\n\nBy leveraging this tool, you can ensure your applications stay informed with the latest data while maintaining a commitment to user privacy. As the demand for real-time, accurate information grows, `DuckDuckGoSearchRun` stands out as a key enabler for innovative and privacy-conscious solutions.","metadata":{}}]}