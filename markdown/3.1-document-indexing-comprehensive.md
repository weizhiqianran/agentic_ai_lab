## LangChain 文档索引综合指南

## **介绍**

**LangChain 索引 API** 是一种强大的工具，旨在简化将文档加载和同步到向量存储的过程。它解决了常见的挑战，例如避免重复内容、重写未更改的内容以及不必要地重新计算嵌入。通过利用 **Record Manager**，该 API 跟踪文档写入，并确保仅处理新的或更新的内容，从而节省时间和计算资源。这使其成为维护最新和高效的向量存储的理想解决方案，即使文档经过多次转换（例如，文本分块）。

该 API 支持多种**删除模式**，允许用户选择在索引期间如何处理向量存储中的现有文档。无论您需要避免自动清理、持续清理旧版本，还是执行向量存储的完全刷新，LangChain 索引 API 都提供了满足您需求的灵活性。本指南探讨了 API 的关键特性、其删除模式以及如何有效地将其与兼容的向量存储一起使用。

### **删除模式的比较**

| **特性**                         | **None**                 | **Incremental**          | **Full**                  | **Scoped_Full**            |
| ----------------------------------- | -------------------------- | -------------------------- | --------------------------- | ---------------------------- |
| **删除重复内容**                     | ✅                         | ✅                         | ✅                          | ✅                           |
| **可并行化**                       | ✅                         | ✅                         | ❌                          | ✅                           |
| **清理已删除的源文档**               | ❌                         | ❌                         | ✅                          | ❌                           |
| **清理源/派生文档的变更**           | ❌                         | ✅                         | ✅                          | ✅                           |
| **清理时机**                       | -                          | 持续进行                   | 索引结束时                  | 索引结束时                   |
| **最佳用例**                       | 手动控制删除；无自动清理。 | 频繁更新，旧版本和新版本之间的重叠最小。 | 完整的数据集刷新或处理源文档的删除。 | 使用并行处理进行部分数据集刷新。 |

### **如何使用此表**

- **删除重复内容**：检查该模式是否避免重新索引重复内容。
- **可并行化**：确定该模式是否支持并行处理以加快索引速度。
- **清理已删除的源文档**：查看该模式是否自动删除不再存在于输入中的文档。
- **清理变更**：检查该模式是否处理对源文档或派生文档的更新。
- **清理时机**：了解清理发生的时间（持续进行或在索引结束时）。
- **最佳用例**：将该模式与您的特定工作流程需求相匹配。

---

## 准备工作

### 安装所需的库

本节安装使用 LangChain、OpenAI 嵌入和 Chroma 向量存储所需的 Python 库。这些库包括：

- `langchain-openai`：提供与 OpenAI 的嵌入模型集成。
- `langchain_community`：包含社区贡献的 LangChain 模块和工具。
- `langchain_experimental`：包含 LangChain 的实验性特性和实用程序。
- `langchain-chroma`：启用与 Chroma 向量数据库的集成。
- `chromadb`：Chroma 向量数据库的核心库。

```python
!pip install -qU langchain-openai
!pip install -qU langchain_community
!pip install -qU langchain_experimental
!pip install -qU langchain-chroma>=0.1.2
!pip install -qU chromadb
```

```
    [输出内容...]
```

### 初始化 OpenAI 嵌入

本节演示如何使用 Kaggle 的 `UserSecretsClient` 安全地获取 OpenAI API 密钥，并初始化 OpenAI 嵌入模型。 `OpenAIEmbeddings` 类用于创建嵌入模型实例，该实例将用于将文本转换为数值嵌入。

关键步骤：

1. **获取 API 密钥**：使用 Kaggle 的 `UserSecretsClient` 安全地检索 OpenAI API 密钥。
2. **初始化嵌入**：使用 `text-embedding-3-small` 模型和获取的 API 密钥初始化 `OpenAIEmbeddings` 类。

此设置确保嵌入模型已准备好用于下游任务，例如缓存嵌入或创建向量存储。

```python
from langchain_openai import OpenAIEmbeddings
from kaggle_secrets import UserSecretsClient

# 安全地获取 API 密钥
user_secrets = UserSecretsClient()
my_api_key = user_secrets.get_secret("api-key-openai")

# 初始化 OpenAI 嵌入
embed = OpenAIEmbeddings(model="text-embedding-3-small", api_key=my_api_key)
```

---

## 1. **None 删除模式**

此模式**不执行旧内容的自动清理**。它确保不会重新索引重复内容，但除非显式删除，否则会保持现有文档不变。

### **None 删除模式的关键特性**

1. **无自动清理**：向量存储中的现有文档**不会被删除**，即使它们不再是输入的一部分。
2. **去重**：确保**不会重新索引**重复内容，从而节省时间和资源。
3. **手动控制**：您保留对文档删除的完全控制权，使其适用于您想要显式管理删除的场景。

### **何时使用 None 删除模式**

- 当您想要**避免自动删除**现有文档时。
- 当您需要**手动管理**向量存储中文档的生命周期时。
- 当您想要确保在索引期间**没有意外的数据丢失**时。

```python
from langchain.indexes import SQLRecordManager, index
from langchain_core.documents import Document
from langchain_chroma import Chroma

# 使用 OpenAI 嵌入初始化 Chroma Vectorstore
collection_name = "test_index"
vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)

# 初始化记录管理器以跟踪文档写入
namespace = f"chroma/{collection_name}"
record_manager = SQLRecordManager(namespace, db_url="sqlite:///record_manager_cache.sql")
record_manager.create_schema()

# 定义测试文档
doc1 = Document(page_content="kitty", metadata={"source": "kitty.txt"})
doc2 = Document(page_content="doggy", metadata={"source": "doggy.txt"})

# 用于清除内容的辅助函数（用于设置）
def _clear():
    index([], record_manager, vectorstore, cleanup="full", source_id_key="source")

# 清除向量存储和记录管理器（设置为干净状态）
_clear()
```

```python
# 使用 None 删除模式索引文档
# 特性：不自动清理旧内容
# 说明：即使多次提供 `doc1`，也只会添加一个唯一文档。
index([doc1, doc1, doc1, doc1, doc1], record_manager, vectorstore, cleanup=None, source_id_key="source")
```

```
    {'num_added': 1, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
```

```python
# 索引新文档
# 说明：`doc1` 被跳过（已索引），并且 `doc2` 被添加。
index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key="source")
```

```
    {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 0}
```

```python
# 第二次运行跳过所有内容
# 说明：两个文档都已索引，因此未添加或更新任何内容。
index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key="source")
```

```
    {'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}
```

---

## 2. **Incremental 删除模式**

此模式在索引新版本时**持续清理旧版本的内容**。它通过删除过时的文档来保持向量存储的最新状态，同时最大限度地减少新旧版本共存的时间窗口。

### **Incremental 删除模式的关键特性**

1. **持续清理**：在索引新版本时，**自动删除**旧版本的文档，确保向量存储反映最新的内容。
2. **高效更新**：仅处理**已更改或新的文档**，避免不必要地重新索引未更改的内容。
3. **最小化重叠**：最小化新旧版本共存的时间窗口，降低返回过时结果的风险。

### **何时使用 Incremental 删除模式**

- 当您想要**保持向量存储与文档的最新版本同步**时。
- 当您需要**高效处理源文档的频繁更新**时。
- 当您想要**避免向量存储的完整重建**，同时确保一致性时。

### **示例工作流程**

1. **初始索引**：将文档添加到向量存储。
2. **后续更新**：更新或添加新文档。过时的版本会自动清理。
3. **无变更**：如果未检测到任何更改，则跳过该过程，从而节省时间和资源。

```python
from langchain.indexes import SQLRecordManager, index
from langchain_core.documents import Document
from langchain_chroma import Chroma

# 使用 OpenAI 嵌入初始化 Chroma Vectorstore
collection_name = "test_index"
vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)

# 初始化记录管理器以跟踪文档写入
namespace = f"chroma/{collection_name}"
record_manager = SQLRecordManager(namespace, db_url="sqlite:///record_manager_cache.sql")
record_manager.create_schema()

# 定义测试文档
doc1 = Document(page_content="kitty", metadata={"source": "kitty.txt"})
doc2 = Document(page_content="doggy", metadata={"source": "doggy.txt"})

# 用于清除内容的辅助函数（用于设置）
def _clear():
    index([], record_manager, vectorstore, cleanup="full", source_id_key="source")

# 清除向量存储和记录管理器（设置为干净状态）
_clear()
```

```python
# 使用 Incremental 删除模式索引文档
# 特性：自动清理旧版本的内容
# 说明：两个文档都已添加到向量存储。
index([doc1, doc2], record_manager, vectorstore, cleanup="incremental", source_id_key="source")
```

```
    {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
```

```python
# 第二次运行跳过两个文档（无变更）
# 说明：未检测到任何更改，因此跳过这两个文档。
index([doc1, doc2], record_manager, vectorstore, cleanup="incremental", source_id_key="source")
```

```
    {'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}
```

```python
# 如果未提供任何文档，则无变更
# 说明：未提供任何文档，因此未添加或删除任何内容。
index([], record_manager, vectorstore, cleanup="incremental", source_id_key="source")
```

```
    {'num_added': 0, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
```

```python
# 更改文档并索引新版本
# 说明：添加了 `doc2` 的新版本，并删除了旧版本。
changed_doc_2 = Document(page_content="puppy", metadata={"source": "doggy.txt"})
index([changed_doc_2], record_manager, vectorstore, cleanup="incremental", source_id_key="source")
```

```
    {'num_added': 1, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 1}
```

---

## 3. **Full 删除模式**

此模式确保**仅保留当前批次中提供的文档**在向量存储中。 **自动删除**未包含在批次中的任何现有文档。 这对于处理**源文档的删除**或执行**完整的数据集刷新**特别有用。

### **Full 删除模式的关键特性**

1. **完全控制**：确保向量存储**仅包含当前批次中显式提供的文档**。
2. **处理删除**：自动删除不再是输入一部分的文档，使其成为**删除过时或已删除的源文档**的理想选择。
3. **数据集刷新**：适用于需要使用新的文档集执行向量存储的**完整刷新**的场景。

### **何时使用 Full 删除模式**

- 当您想要**确保向量存储与您在当前批次中提供的文档完全匹配**时。
- 当您需要**处理源文档的删除**时（例如，不再存在的文件或记录）。
- 当执行**完整的数据集刷新**或替换向量存储的全部内容时。

### **示例工作流程**

1. **初始索引**：将一组文档添加到向量存储。
2. **后续更新**：提供一批新的文档。 未包含在批次中的任何文档都将**自动删除**。
3. **处理删除**：如果从输入中删除源文档，则也会从向量存储中删除。

```python
from langchain.indexes import SQLRecordManager, index
from langchain_core.documents import Document
from langchain_chroma import Chroma

# 使用 OpenAI 嵌入初始化 Chroma Vectorstore
collection_name = "test_index"
vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)

# 初始化记录管理器以跟踪文档写入
namespace = f"chroma/{collection_name}"
record_manager = SQLRecordManager(namespace, db_url="sqlite:///record_manager_cache.sql")
record_manager.create_schema()

# 定义测试文档
doc1 = Document(page_content="kitty", metadata={"source": "kitty.txt"})
doc2 = Document(page_content="doggy", metadata={"source": "doggy.txt"})

# 用于清除内容的辅助函数（用于设置）
def _clear():
    index([], record_manager, vectorstore, cleanup="full", source_id_key="source")

# 清除向量存储和记录管理器（设置为干净状态）
_clear()
```

```python
# 使用 Full 删除模式索引文档
# 特性：仅保留提供的文档；其他文档将被删除
# 说明：两个文档都已添加到向量存储。
all_docs = [doc1, doc2]
index(all_docs, record_manager, vectorstore, cleanup="full", source_id_key="source")
```

```
    {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
```

```python
# 模拟删除第一个文档（例如，不再需要“kitty.txt”）
del all_docs[0]  # 从批次中删除 `doc1`
# 说明：从向量存储中删除了 `doc1`，因为它不再在批次中。
index(all_docs, record_manager, vectorstore, cleanup="full", source_id_key="source")
```

```
    {'num_added': 0, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}
```

---

## 4. **Scoped_Full 删除模式**

### **Scoped_Full 删除模式的关键特性**

1. **部分数据集刷新**：仅更新和清理指定范围内的文档（例如，“kitty.txt”和“doggy.txt”）。
2. **并行处理**：支持并行执行，使其对于大型数据集来说非常高效。
3. **在索引结束时清理**：在新版本的文档索引后，将删除旧版本。
4. **不清理不相关的文档**：范围之外的文档（例如，“birdie.txt”）将保持不变。

### **何时使用 Scoped_Full 删除模式**

- 当您需要**更新向量存储中的一部分文档**而不影响其余部分时。
- 当您想要**利用并行处理**以加快索引速度时。
- 当您需要在更新特定文档后**清理旧版本**时。

### **工作流程摘要**

1. **初始设置**：使用 **Full 删除模式** 将初始文档集填充到向量存储中。
2. **部分更新**：使用 **Scoped_Full 删除模式** 仅更新和清理指定的文档。
3. **验证**：检查向量存储以确保正确应用了更新并且不相关的文档保持不变。

```python
from langchain.indexes import SQLRecordManager, index
from langchain_core.documents import Document
from langchain_chroma import Chroma

# 使用 OpenAI 嵌入初始化 Chroma Vectorstore
collection_name = "test_index"
vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)

# 初始化记录管理器以跟踪文档写入
namespace = f"chroma/{collection_name}"
record_manager = SQLRecordManager(namespace, db_url="sqlite:///record_manager_cache.sql")
record_manager.create_schema()

# 定义测试文档
doc1 = Document(page_content="kitty", metadata={"source": "kitty.txt"})
doc2 = Document(page_content="doggy", metadata={"source": "doggy.txt"})
doc3 = Document(page_content="birdie", metadata={"source": "birdie.txt"})

# 用于清除内容的辅助函数（用于设置）
def _clear():
    index([], record_manager, vectorstore, cleanup="full", source_id_key="source")

# 清除向量存储和记录管理器（设置为干净状态）
_clear()
```

```python
# 使用 Full 删除模式进行初始索引，以填充向量存储
all_docs = [doc1, doc2, doc3]
index(all_docs, record_manager, vectorstore, cleanup="full", source_id_key="source")
```

```
    {'num_added': 3, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
```

```python
# 模拟部分更新：仅更新与“kitty.txt”和“doggy.txt”相关的文档
updated_doc1 = Document(page_content="kitty v2", metadata={"source": "kitty.txt"})
updated_doc2 = Document(page_content="doggy v2", metadata={"source": "doggy.txt"})

# 使用 Scoped_Full 删除模式仅更新指定的文档
# - 删除 `doc1` 和 `doc2` 的旧版本。
# - 添加 `doc1` 和 `doc2` 的新版本。
# - `doc3` 在向量存储中保持不变。
index([updated_doc1, updated_doc2], record_manager, vectorstore, cleanup="scoped_full", source_id_key="source")
```

```
    {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 2}
```

```python
# 验证更新后的向量存储
results = vectorstore.similarity_search("kitty", k=5)
for result in results:
    print(result.page_content)
```

```
    kitty v2
    doggy v2
    birdie
```

## **结论**

**LangChain 索引 API** 是一种用于管理向量存储中文档的多功能且高效的解决方案。通过自动执行诸如去重、避免不必要的重新计算以及处理文档删除等任务，它大大降低了维护最新的向量存储的复杂性和成本。多种**删除模式**的可用性可确保您可以根据自己的特定需求定制索引过程，无论您需要手动控制、持续更新还是完整的数据集刷新。

在选择删除模式时，请考虑以下事项：

- 当您想要完全控制删除并且没有自动清理时，使用 **None 删除模式**。
- 对于频繁更新且新旧版本之间的重叠最小的情况，请使用 **Incremental 删除模式**。
- 对于完整的数据集刷新或处理源文档的删除，请使用 **Full 删除模式**。
- 对于使用并行处理进行部分数据集刷新，请使用 **Scoped_Full 删除模式**。

通过了解每种模式的优势和用例，您可以优化索引工作流程，并确保向量存储保持准确、高效和最新。 LangChain 索引 API 与广泛的向量存储的兼容性使其成为涉及文档索引和检索的任何应用程序的重要工具。
